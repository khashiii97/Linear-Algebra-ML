{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrQrcHdwqOSF"
   },
   "source": [
    "# <font color='black'>EE25737: Introduction to Machine Learning</font>\n",
    "## <font color='black'>Fall 99-00, Group 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_2En8SlqOSU"
   },
   "source": [
    "### Arman Hafizi\n",
    "### 95105516"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8_9ZcpDPupS"
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya-k1E03PqAC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612710453777E12,
     "user_tz": -210.0,
     "elapsed": 27313.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "0eb557ff-b999-46b1-e8a6-5019fe5f19d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1wdyrNdvRhx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612710457473E12,
     "user_tz": -210.0,
     "elapsed": 2047.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "52436f79-ae92-4810-fe7d-d8d453b121c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/dataset\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWt3TIAUuzHy"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ggb5eEuQu10e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612712009235E12,
     "user_tz": -210.0,
     "elapsed": 1057.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "import time\r\n",
    "import random\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\r\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment\r\n",
    "\r\n",
    "from keras.optimizers import SGD\r\n",
    "from keras.utils import to_categorical\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL3fvWVhqOSX"
   },
   "source": [
    "# C4: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UHZggswqOSZ"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Voaot_v2qOSa"
   },
   "source": [
    "For installing Pytorch, run the following code: (if you don't use Jupter Notebook, first you should install pip command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKT-qmnhqOSc"
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZJuBaicqOSf"
   },
   "source": [
    "Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srZbl7ulqOSg"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w1uK9GEqOSh"
   },
   "source": [
    "For installing Keras, first you should install Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvV4kVdrqOSi"
   },
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7kl3GQiqOSl"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4vXTsVOqOSp"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Code for loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d13USti9qOSq"
   },
   "source": [
    "## C4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pB9rL13qOSr"
   },
   "outputs": [],
   "source": [
    "## Part 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g13Zw9kBqOSt"
   },
   "source": [
    "## C4.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELVn8OZ_qOSu"
   },
   "outputs": [],
   "source": [
    "## Part 2.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvgYaJMVqOSu"
   },
   "source": [
    "## C4.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhReCRt6qOSv"
   },
   "outputs": [],
   "source": [
    "## Part 3.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2brLWtFeqOSv"
   },
   "source": [
    "# C5. Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-ADWdL7qOSw"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyuqYtmSwJdA"
   },
   "outputs": [],
   "source": [
    "# read file\r\n",
    "df = pd.read_csv('fashion-mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbD-GpFCqOSx"
   },
   "outputs": [],
   "source": [
    "# split X and Y\n",
    "Y = df['y']\n",
    "X = df.drop(labels=df.columns[-1], axis='columns', inplace=False)\n",
    "# print(X)\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT6sYtHYxgeK"
   },
   "outputs": [],
   "source": [
    "# split train val test\r\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=1)\r\n",
    "# print(X_train)\r\n",
    "# print(Y_train)\r\n",
    "# print(X_test)\r\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeqF_PxR-dX5"
   },
   "source": [
    "## Assistive Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDkGM0Kl-c7e"
   },
   "outputs": [],
   "source": [
    "def get_metrics(model, X_train, Y_train, X_test, Y_test):\r\n",
    "    # check accracy on training set\r\n",
    "    train_acc = model.score(X_train, Y_train)\r\n",
    "    # predict on test on\r\n",
    "    Y_pred = model.predict(X_test)\r\n",
    "    # check accracy on test set\r\n",
    "    test_acc = accuracy_score(Y_test, Y_pred)\r\n",
    "    # create confusion matrix\r\n",
    "    conf_mat = confusion_matrix(Y_test, Y_pred)\r\n",
    "    return train_acc, test_acc, Y_pred, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBB0YKkmqOS_"
   },
   "source": [
    "## C5.1. SVM with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcK88rGIqOS_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612609172408E12,
     "user_tz": -210.0,
     "elapsed": 8952.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "4b0a695f-d140-4885-e6a1-91a3c0fb15e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "clf_5_1 = svm.SVC(kernel = 'linear')\n",
    "# fit the model\n",
    "clf_5_1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kaus86hQ-If0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.61260930865E12,
     "user_tz": -210.0,
     "elapsed": 28740.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "d291c51c-c954-49f3-acfc-ea35dda070c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  81.12\n",
      "Predicted Values:  [3 8 2 ... 5 5 6]\n",
      "Confusion Matrix:\n",
      " [[384   6  14  18   6   0  60   0   5   0]\n",
      " [  4 462   5   5   0   0   0   0   0   0]\n",
      " [ 13   2 384   6  54   0  56   0   8   0]\n",
      " [ 43  22  10 381  10   0  12   0   2   0]\n",
      " [  6   0  95  19 325   0  52   0   3   0]\n",
      " [  0   1   0   0   0 433   0  42   4  15]\n",
      " [ 85   2  66  12  47   0 273   0   8   0]\n",
      " [  0   0   0   0   0  22   0 477   2  21]\n",
      " [  6   2   8   1   0   3  12   1 465   2]\n",
      " [  0   0   0   0   0  15   0  31   0 472]]\n"
     ]
    }
   ],
   "source": [
    "# get metrics of the model\r\n",
    "train_acc, test_acc, Y_pred, conf_mat = get_metrics(clf_5_1, X_train, Y_train, X_test, Y_test)\r\n",
    "print('Train Accuracy: ', round(train_acc*100, 2))\r\n",
    "print('Test Accuracy: ', round(test_acc*100, 2))\r\n",
    "print('Predicted Values: ', Y_pred)\r\n",
    "print('Confusion Matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_wzUsHqOTB"
   },
   "source": [
    "## C5.2. SVM with gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9TxTwemA-Dg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612611086027E12,
     "user_tz": -210.0,
     "elapsed": 1266805.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "d4c84dee-5d53-4635-c5b4-82e7f3ea44bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.1\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.2\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.30000000000000004\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.4\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.5\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.6000000000000001\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.7000000000000001\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.8\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  0.9\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n",
      "Gamma:  1.0\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\r\n",
    "best_gamma = 0\r\n",
    "for i in range(10):\r\n",
    "    g = (i+1) * 0.1\r\n",
    "    # create the model\r\n",
    "    clf = svm.SVC(gamma = g, kernel = 'rbf')\r\n",
    "    # fit the model\r\n",
    "    clf.fit(X_train, Y_train)\r\n",
    "    # get metrics of the model\r\n",
    "    train_acc, test_acc, Y_pred, conf_mat = get_metrics(clf, X_train, Y_train, X_test, Y_test)\r\n",
    "    print('Gamma: ', g)\r\n",
    "    print('Train Accuracy: ', round(train_acc*100, 2))\r\n",
    "    print('Test Accuracy: ', round(test_acc*100, 2))\r\n",
    "    print('Predicted Values: ', Y_pred)\r\n",
    "    print('Confusion Matrix:\\n', conf_mat)\r\n",
    "    print('-----------------------------------------------------------------')\r\n",
    "    # update best gamma\r\n",
    "    if test_acc > best_acc:\r\n",
    "        best_acc = test_acc\r\n",
    "        best_gamma = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl_CuR6xJ2-m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612611868339E12,
     "user_tz": -210.0,
     "elapsed": 888.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "8ef39174-5aac-4c9d-e0c9-fa47d771298f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gamma:  0.1\n",
      "Best Accuracy on test set:  9.6\n"
     ]
    }
   ],
   "source": [
    "print('Best Gamma: ', best_gamma)\r\n",
    "print('Best Accuracy on test set: ', round(100*best_acc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w7XS99GqOTC"
   },
   "source": [
    "## C5.3. K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKemFvbFqOTD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612613767214E12,
     "user_tz": -210.0,
     "elapsed": 1375062.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "9e8513fc-dde2-4a4e-faf0-5d0ad467e1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K (Number of Neighbors):  1\n",
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  79.26\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[374   3  14  14   3   0  80   0   5   0]\n",
      " [  6 456   5   6   0   0   3   0   0   0]\n",
      " [ 10   0 342   3  87   0  80   0   1   0]\n",
      " [ 38  10  10 374  27   0  20   0   1   0]\n",
      " [  0   0  72  27 326   0  75   0   0   0]\n",
      " [  1   0   0   0   1 371   1  65   5  51]\n",
      " [ 83   1  61  13  43   0 288   0   4   0]\n",
      " [  0   0   0   0   0   4   0 467   2  49]\n",
      " [  4   0  12   3   2   0   5   5 469   0]\n",
      " [  0   0   0   0   0   3   0  17   2 496]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  2\n",
      "Train Accuracy:  90.86\n",
      "Test Accuracy:  80.16\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[434   2  19  12   1   0  21   0   4   0]\n",
      " [  8 457   6   3   0   0   2   0   0   0]\n",
      " [ 17   0 409   7  60   0  30   0   0   0]\n",
      " [ 51  18  13 379  13   0   6   0   0   0]\n",
      " [  0   0 129  39 314   0  18   0   0   0]\n",
      " [  2   0   0   3   1 411   1  49   2  26]\n",
      " [128   1  96  12  56   0 197   0   3   0]\n",
      " [  0   0   0   0   1   5   0 493   0  23]\n",
      " [  6   0  18   5   4   2   9   9 447   0]\n",
      " [  0   0   0   0   0   4   0  47   0 467]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  3\n",
      "Train Accuracy:  88.8\n",
      "Test Accuracy:  80.64\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[411   3  11   9   2   0  52   0   5   0]\n",
      " [  9 451   7   6   1   0   2   0   0   0]\n",
      " [ 14   0 373   7  66   0  59   0   4   0]\n",
      " [ 38   6  10 399  19   0   7   0   1   0]\n",
      " [  1   0 100  22 334   0  43   0   0   0]\n",
      " [  3   0   1   3   2 372   0  70   3  41]\n",
      " [104   1  82   8  42   0 253   0   3   0]\n",
      " [  0   0   0   0   1   3   0 477   0  41]\n",
      " [  6   0  15   3   2   1   3   5 465   0]\n",
      " [  0   0   0   0   0   3   0  18   0 497]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  4\n",
      "Train Accuracy:  86.8\n",
      "Test Accuracy:  81.08\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[419   3  15   9   3   0  40   0   4   0]\n",
      " [  9 455   5   5   1   0   1   0   0   0]\n",
      " [ 11   0 386   7  64   0  52   0   3   0]\n",
      " [ 42   7   7 399  14   0  11   0   0   0]\n",
      " [  1   0  91  30 334   0  44   0   0   0]\n",
      " [  3   0   1   3   1 373   0  76   2  36]\n",
      " [107   1  78  11  45   0 248   0   3   0]\n",
      " [  0   0   0   0   0   2   0 489   0  31]\n",
      " [  5   0  12   4   3   0   5   8 463   0]\n",
      " [  0   0   0   0   0   4   0  26   0 488]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  5\n",
      "Train Accuracy:  85.66\n",
      "Test Accuracy:  81.08\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[412   3  12  13   2   0  45   0   6   0]\n",
      " [ 10 451   6   7   1   0   1   0   0   0]\n",
      " [ 13   0 368   4  80   0  54   0   4   0]\n",
      " [ 37   3   7 409  16   0   8   0   0   0]\n",
      " [  2   0  87  20 349   0  42   0   0   0]\n",
      " [  1   0   0   2   2 360   1  85   2  42]\n",
      " [102   1  71   8  46   0 262   0   3   0]\n",
      " [  0   0   0   0   0   1   0 480   0  41]\n",
      " [  5   0  10   3   4   0   6   7 464   1]\n",
      " [  0   0   0   0   0   3   0  16   0 499]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  6\n",
      "Train Accuracy:  85.06\n",
      "Test Accuracy:  81.04\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[420   2  13  14   3   0  37   0   4   0]\n",
      " [  9 450   8   7   1   0   1   0   0   0]\n",
      " [ 12   0 369   7  73   0  58   0   4   0]\n",
      " [ 39   5   7 408  15   0   5   0   1   0]\n",
      " [  2   0  82  28 340   0  48   0   0   0]\n",
      " [  2   0   1   1   2 364   0  79   3  43]\n",
      " [108   1  75  10  36   0 259   0   4   0]\n",
      " [  0   0   0   0   0   3   0 486   0  33]\n",
      " [  4   0  11   4   4   0   5   9 463   0]\n",
      " [  0   0   0   0   0   3   0  22   0 493]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  7\n",
      "Train Accuracy:  84.38\n",
      "Test Accuracy:  80.66\n",
      "Predicted Values:  [6 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[416   2  14  13   3   0  40   0   5   0]\n",
      " [  9 445   8  10   1   0   3   0   0   0]\n",
      " [  8   0 362   4  80   0  64   0   5   0]\n",
      " [ 37   3   7 404  20   0   8   0   1   0]\n",
      " [  2   0  78  17 354   0  49   0   0   0]\n",
      " [  3   0   0   1   1 347   1  95   2  45]\n",
      " [103   1  70  11  33   0 270   0   5   0]\n",
      " [  0   0   0   0   0   2   0 474   0  46]\n",
      " [  4   0  13   3   3   0   5  10 462   0]\n",
      " [  0   0   0   0   0   4   0  15   0 499]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  8\n",
      "Train Accuracy:  84.1\n",
      "Test Accuracy:  80.76\n",
      "Predicted Values:  [6 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[422   2  14  14   3   0  33   0   5   0]\n",
      " [ 10 443  10  10   1   0   2   0   0   0]\n",
      " [  9   0 360   5  77   0  67   0   5   0]\n",
      " [ 40   5   7 404  17   0   7   0   0   0]\n",
      " [  1   0  74  20 357   0  48   0   0   0]\n",
      " [  3   0   0   2   2 358   2  82   2  44]\n",
      " [111   1  72  10  37   0 256   0   6   0]\n",
      " [  0   0   0   0   0   3   0 480   0  39]\n",
      " [  2   0  11   4   4   0   7  10 462   0]\n",
      " [  0   0   0   0   0   3   0  19   0 496]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  9\n",
      "Train Accuracy:  83.6\n",
      "Test Accuracy:  80.28\n",
      "Predicted Values:  [6 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[417   2  12  15   3   0  38   0   6   0]\n",
      " [  9 443   9  12   1   0   2   0   0   0]\n",
      " [  8   0 360   4  76   0  70   0   5   0]\n",
      " [ 38   5   8 397  24   0   8   0   0   0]\n",
      " [  2   0  71  16 365   0  46   0   0   0]\n",
      " [  5   0   1   1   0 343   1  95   3  46]\n",
      " [112   1  72  11  34   0 257   0   6   0]\n",
      " [  0   0   0   0   0   2   0 476   0  44]\n",
      " [  2   0  16   4   5   0   5  10 458   0]\n",
      " [  0   0   0   0   0   3   0  17   0 498]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  10\n",
      "Train Accuracy:  83.52\n",
      "Test Accuracy:  80.94\n",
      "Predicted Values:  [6 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[420   2  13  16   4   0  34   0   4   0]\n",
      " [  9 443   9  12   1   0   2   0   0   0]\n",
      " [  8   0 365   5  77   0  63   0   5   0]\n",
      " [ 34   5   7 407  17   0   9   0   1   0]\n",
      " [  2   0  69  19 362   0  48   0   0   0]\n",
      " [  4   0   1   1   0 352   2  89   2  44]\n",
      " [109   1  67  12  35   0 263   0   6   0]\n",
      " [  0   0   0   0   0   2   0 482   0  38]\n",
      " [  3   0  13   4   4   0   5  13 458   0]\n",
      " [  0   0   0   0   0   3   0  20   0 495]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  11\n",
      "Train Accuracy:  82.84\n",
      "Test Accuracy:  80.36\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[413   2  12  15   3   0  43   0   5   0]\n",
      " [ 10 442  10  11   1   0   2   0   0   0]\n",
      " [  8   0 358   5  78   0  69   0   5   0]\n",
      " [ 36   5   6 402  19   0  12   0   0   0]\n",
      " [  1   0  69  18 372   0  40   0   0   0]\n",
      " [  3   0   1   1   0 346   3  91   2  48]\n",
      " [112   1  71  11  35   0 257   0   6   0]\n",
      " [  0   0   0   0   0   1   1 474   0  46]\n",
      " [  3   0  14   4   3   0   6  13 456   1]\n",
      " [  0   0   0   0   0   2   0  18   0 498]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  12\n",
      "Train Accuracy:  82.62\n",
      "Test Accuracy:  80.46\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[420   2  12  12   6   0  36   0   5   0]\n",
      " [ 11 442  10   9   1   0   3   0   0   0]\n",
      " [  8   0 363   6  76   0  64   0   6   0]\n",
      " [ 33   6   6 403  19   0  13   0   0   0]\n",
      " [  1   0  74  19 363   0  43   0   0   0]\n",
      " [  2   0   0   1   0 346   5  92   2  47]\n",
      " [114   1  68  11  38   0 255   0   6   0]\n",
      " [  0   0   0   0   0   3   1 481   0  37]\n",
      " [  2   0  15   4   3   0   8  14 454   0]\n",
      " [  0   0   0   0   0   3   0  19   0 496]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  13\n",
      "Train Accuracy:  82.68\n",
      "Test Accuracy:  79.92\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[420   2  12  14   6   0  34   0   5   0]\n",
      " [  9 444  10   9   1   0   3   0   0   0]\n",
      " [  9   0 350   6  84   0  68   0   6   0]\n",
      " [ 39   5   6 398  22   0   9   0   1   0]\n",
      " [  2   0  69  18 365   0  46   0   0   0]\n",
      " [  1   0   1   1   1 337   3 100   2  49]\n",
      " [104   1  66  14  40   0 262   0   6   0]\n",
      " [  0   0   0   0   0   4   0 471   0  47]\n",
      " [  1   0  15   4   4   0  10  14 452   0]\n",
      " [  0   0   0   0   0   3   0  18   0 497]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  14\n",
      "Train Accuracy:  82.24\n",
      "Test Accuracy:  80.16\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[428   2  14  15   5   0  24   0   5   0]\n",
      " [ 10 444  10   9   1   0   2   0   0   0]\n",
      " [  9   0 345   6  88   0  69   0   6   0]\n",
      " [ 35   4   6 404  20   0  10   0   1   0]\n",
      " [  2   0  76  20 359   0  43   0   0   0]\n",
      " [  1   0   1   1   1 346   4  92   2  47]\n",
      " [107   1  67  14  40   0 259   0   5   0]\n",
      " [  0   0   0   0   0   4   0 474   0  44]\n",
      " [  1   0  14   4   4   0  10  15 452   0]\n",
      " [  0   0   0   0   0   3   0  18   0 497]]\n",
      "-----------------------------------------------------------------\n",
      "K (Number of Neighbors):  15\n",
      "Train Accuracy:  81.42\n",
      "Test Accuracy:  80.18\n",
      "Predicted Values:  [0 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[427   2  16  15   4   0  24   0   5   0]\n",
      " [ 10 444  10   9   1   0   2   0   0   0]\n",
      " [  7   0 351   6  79   0  75   0   5   0]\n",
      " [ 36   3   7 404  20   0   9   0   1   0]\n",
      " [  1   0  71  20 365   0  43   0   0   0]\n",
      " [  2   0   1   1   0 334   3 101   2  51]\n",
      " [104   1  63  16  41   0 263   0   5   0]\n",
      " [  0   0   0   0   0   3   0 473   0  46]\n",
      " [  1   0  13   4   5   0  12  14 451   0]\n",
      " [  0   0   0   0   0   3   0  18   0 497]]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_k = 0\n",
    "for i in range(15):\n",
    "    k = i+1\n",
    "    # create the model\n",
    "    knn = KNeighborsClassifier(n_neighbors = k) # default distance metric is already Euclidean\n",
    "    # fit the model\n",
    "    knn.fit(X_train, Y_train)\n",
    "    # get metrics of the model\n",
    "    train_acc, test_acc, Y_pred, conf_mat = get_metrics(knn, X_train, Y_train, X_test, Y_test)\n",
    "    print('K (Number of Neighbors): ', k)\n",
    "    print('Train Accuracy: ', round(train_acc*100, 2))\n",
    "    print('Test Accuracy: ', round(test_acc*100, 2))\n",
    "    print('Predicted Values: ', Y_pred)\n",
    "    print('Confusion Matrix:\\n', conf_mat)\n",
    "    print('-----------------------------------------------------------------')\n",
    "    # update best gamma\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgkxPHBWMT93",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612613781058E12,
     "user_tz": -210.0,
     "elapsed": 1041.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "a3bbfc1c-f063-4dfe-cb49-450364769aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K:  4\n",
      "Best Accuracy on test set:  81.08\n"
     ]
    }
   ],
   "source": [
    "print('Best K: ', best_k)\r\n",
    "print('Best Accuracy on test set: ', round(100*best_acc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jFNDFOiqOTD"
   },
   "source": [
    "## C5.4. Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6vpLGX3qOTE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612613818463E12,
     "user_tz": -210.0,
     "elapsed": 3860.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "6be619d1-c615-4cb3-b0e1-722f925ba696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "tree = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA8y8BstQtKc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612613824821E12,
     "user_tz": -210.0,
     "elapsed": 1018.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "e60090db-d529-4dfc-fd1f-2d1b4b6ea60b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  100.0\n",
      "Test Accuracy:  73.48\n",
      "Predicted Values:  [5 8 6 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[331   2  12  37   7   4  96   1   3   0]\n",
      " [  4 426   5  26   5   1   7   0   2   0]\n",
      " [ 21   1 317   3  92   0  77   1  11   0]\n",
      " [ 30  27   8 351  28   1  25   0   7   3]\n",
      " [  7  10  92  30 279   0  73   0   8   1]\n",
      " [  1   1   0   1   1 418   1  34  18  20]\n",
      " [ 65   2  62  20  53   1 279   1  10   0]\n",
      " [  0   0   0   0   0  48   0 422   8  44]\n",
      " [  1   4   9  10   7  16  15   3 433   2]\n",
      " [  1   1   0   2   1  20   1  67   7 418]]\n"
     ]
    }
   ],
   "source": [
    "# get metrics of the model\r\n",
    "train_acc, test_acc, Y_pred, conf_mat = get_metrics(tree, X_train, Y_train, X_test, Y_test)\r\n",
    "print('Train Accuracy: ', round(train_acc*100, 2))\r\n",
    "print('Test Accuracy: ', round(test_acc*100, 2))\r\n",
    "print('Predicted Values: ', Y_pred)\r\n",
    "print('Confusion Matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqeUewoVqOTE"
   },
   "source": [
    "## C5.5. Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Vi6mLvcqOTF"
   },
   "outputs": [],
   "source": [
    "acts = ['relu', 'sigmoid', 'softmax', 'tanh', 'exponential']\n",
    "# create the models\n",
    "model = []\n",
    "for act1 in acts:\n",
    "    for act2 in acts:\n",
    "        m = Sequential()\n",
    "        m.add(Dense(100, input_dim = 784, activation = act1))\n",
    "        m.add(Dense(100, activation = act2))\n",
    "        m.add(Dense(10, activation = 'softmax'))\n",
    "        model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCIOkK3eYYZ3"
   },
   "outputs": [],
   "source": [
    "# compile the models\r\n",
    "for m in model:\r\n",
    "    m.compile(loss = 'categorical_crossentropy', optimizer = SGD(), metrics=['accuracy'])\r\n",
    "    # m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTs2BSKCUJlI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612619085786E12,
     "user_tz": -210.0,
     "elapsed": 946998.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "6e277640-0843-4a48-df70-90246fb039d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14154.9907 - accuracy: 0.1087 - val_loss: 2.4388 - val_accuracy: 0.0964\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3017 - accuracy: 0.1057 - val_loss: 2.4389 - val_accuracy: 0.0964\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.4390 - val_accuracy: 0.0964\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3010 - accuracy: 0.1120 - val_loss: 2.4392 - val_accuracy: 0.0964\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3002 - accuracy: 0.1085 - val_loss: 2.4394 - val_accuracy: 0.0964\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3009 - accuracy: 0.1072 - val_loss: 2.4395 - val_accuracy: 0.0964\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3001 - accuracy: 0.1043 - val_loss: 2.4397 - val_accuracy: 0.0964\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3016 - accuracy: 0.1022 - val_loss: 2.4398 - val_accuracy: 0.0964\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2992 - accuracy: 0.1122 - val_loss: 2.4400 - val_accuracy: 0.0964\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2995 - accuracy: 0.1123 - val_loss: 2.4401 - val_accuracy: 0.0964\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.1082 - val_loss: 2.4402 - val_accuracy: 0.0964\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3006 - accuracy: 0.1071 - val_loss: 2.4403 - val_accuracy: 0.0964\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3000 - accuracy: 0.1095 - val_loss: 2.4404 - val_accuracy: 0.0964\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3018 - accuracy: 0.1073 - val_loss: 2.4405 - val_accuracy: 0.0964\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2996 - accuracy: 0.1127 - val_loss: 2.4406 - val_accuracy: 0.0964\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3006 - accuracy: 0.0999 - val_loss: 2.4406 - val_accuracy: 0.0964\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3003 - accuracy: 0.1061 - val_loss: 2.4407 - val_accuracy: 0.0964\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2988 - accuracy: 0.1157 - val_loss: 2.4408 - val_accuracy: 0.0964\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3014 - accuracy: 0.1088 - val_loss: 2.4408 - val_accuracy: 0.0964\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2996 - accuracy: 0.1027 - val_loss: 2.4408 - val_accuracy: 0.0964\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2996 - accuracy: 0.1106 - val_loss: 2.4408 - val_accuracy: 0.0964\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2999 - accuracy: 0.1084 - val_loss: 2.4409 - val_accuracy: 0.0964\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3006 - accuracy: 0.1095 - val_loss: 2.4409 - val_accuracy: 0.0964\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3017 - accuracy: 0.1019 - val_loss: 2.4410 - val_accuracy: 0.0964\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3005 - accuracy: 0.1053 - val_loss: 2.4410 - val_accuracy: 0.0964\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3011 - accuracy: 0.0999 - val_loss: 2.4410 - val_accuracy: 0.0964\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2994 - accuracy: 0.1013 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3004 - accuracy: 0.1081 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2987 - accuracy: 0.1099 - val_loss: 2.4410 - val_accuracy: 0.0964\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3011 - accuracy: 0.1078 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1028 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3000 - accuracy: 0.1146 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3001 - accuracy: 0.1105 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3019 - accuracy: 0.1034 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3005 - accuracy: 0.1112 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2989 - accuracy: 0.1066 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3006 - accuracy: 0.1046 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3003 - accuracy: 0.1041 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1035 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2988 - accuracy: 0.1180 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2994 - accuracy: 0.1059 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3006 - accuracy: 0.1015 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3016 - accuracy: 0.1103 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2980 - accuracy: 0.1109 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3004 - accuracy: 0.1050 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3008 - accuracy: 0.1018 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2993 - accuracy: 0.1078 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.0996 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2991 - accuracy: 0.1075 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2985 - accuracy: 0.1081 - val_loss: 2.4411 - val_accuracy: 0.0964\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.8493 - accuracy: 0.4053 - val_loss: 1.2373 - val_accuracy: 0.6210\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1275 - accuracy: 0.6570 - val_loss: 0.9931 - val_accuracy: 0.6676\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9559 - accuracy: 0.6922 - val_loss: 0.9334 - val_accuracy: 0.6598\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8714 - accuracy: 0.6949 - val_loss: 0.8286 - val_accuracy: 0.7144\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7991 - accuracy: 0.7311 - val_loss: 0.7655 - val_accuracy: 0.7198\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7305 - accuracy: 0.7501 - val_loss: 0.7739 - val_accuracy: 0.7086\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7305 - accuracy: 0.7351 - val_loss: 0.7430 - val_accuracy: 0.7284\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7054 - accuracy: 0.7489 - val_loss: 0.6972 - val_accuracy: 0.7488\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6624 - accuracy: 0.7666 - val_loss: 0.6756 - val_accuracy: 0.7648\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6257 - accuracy: 0.7804 - val_loss: 0.6465 - val_accuracy: 0.7748\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.7953 - val_loss: 0.6224 - val_accuracy: 0.7756\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.7831 - val_loss: 0.6627 - val_accuracy: 0.7712\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6013 - accuracy: 0.7882 - val_loss: 0.7335 - val_accuracy: 0.7406\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6171 - accuracy: 0.7829 - val_loss: 0.5837 - val_accuracy: 0.7898\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5646 - accuracy: 0.8022 - val_loss: 0.6085 - val_accuracy: 0.7728\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5577 - accuracy: 0.7923 - val_loss: 0.5807 - val_accuracy: 0.7850\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.8100 - val_loss: 0.5549 - val_accuracy: 0.8082\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5084 - accuracy: 0.8282 - val_loss: 0.5886 - val_accuracy: 0.7990\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5583 - accuracy: 0.8114 - val_loss: 0.6016 - val_accuracy: 0.7842\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.8059 - val_loss: 0.5657 - val_accuracy: 0.7954\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5072 - accuracy: 0.8275 - val_loss: 0.6055 - val_accuracy: 0.7890\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.8078 - val_loss: 0.5959 - val_accuracy: 0.7896\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8223 - val_loss: 0.7009 - val_accuracy: 0.7382\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5161 - accuracy: 0.8145 - val_loss: 0.5416 - val_accuracy: 0.8138\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4852 - accuracy: 0.8358 - val_loss: 0.6050 - val_accuracy: 0.7832\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4991 - accuracy: 0.8244 - val_loss: 0.5464 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4728 - accuracy: 0.8372 - val_loss: 0.5803 - val_accuracy: 0.7932\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4838 - accuracy: 0.8314 - val_loss: 0.5586 - val_accuracy: 0.7998\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.8224 - val_loss: 0.5613 - val_accuracy: 0.7944\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.8384 - val_loss: 0.5583 - val_accuracy: 0.7930\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4520 - accuracy: 0.8363 - val_loss: 0.5975 - val_accuracy: 0.7808\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5005 - accuracy: 0.8229 - val_loss: 0.5181 - val_accuracy: 0.8122\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.8350 - val_loss: 0.5844 - val_accuracy: 0.7912\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4376 - accuracy: 0.8490 - val_loss: 0.5024 - val_accuracy: 0.8230\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8454 - val_loss: 0.5988 - val_accuracy: 0.7824\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4432 - accuracy: 0.8397 - val_loss: 0.5096 - val_accuracy: 0.8258\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8532 - val_loss: 0.5279 - val_accuracy: 0.8164\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4666 - accuracy: 0.8344 - val_loss: 0.5185 - val_accuracy: 0.8188\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.8564 - val_loss: 0.5261 - val_accuracy: 0.8204\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4097 - accuracy: 0.8562 - val_loss: 0.5508 - val_accuracy: 0.7882\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4161 - accuracy: 0.8490 - val_loss: 0.4907 - val_accuracy: 0.8286\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4203 - accuracy: 0.8514 - val_loss: 0.5472 - val_accuracy: 0.8044\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8538 - val_loss: 0.5450 - val_accuracy: 0.8058\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8524 - val_loss: 0.5121 - val_accuracy: 0.8242\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8580 - val_loss: 0.4927 - val_accuracy: 0.8306\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4165 - accuracy: 0.8503 - val_loss: 0.5123 - val_accuracy: 0.8272\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4087 - accuracy: 0.8531 - val_loss: 0.5011 - val_accuracy: 0.8270\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3980 - accuracy: 0.8559 - val_loss: 0.4933 - val_accuracy: 0.8362\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4004 - accuracy: 0.8589 - val_loss: 0.4860 - val_accuracy: 0.8324\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3914 - accuracy: 0.8639 - val_loss: 0.4981 - val_accuracy: 0.8362\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2724 - accuracy: 0.1051 - val_loss: 2.2340 - val_accuracy: 0.1860\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2184 - accuracy: 0.2628 - val_loss: 2.2113 - val_accuracy: 0.2098\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1812 - accuracy: 0.2641 - val_loss: 2.1532 - val_accuracy: 0.2806\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1356 - accuracy: 0.2930 - val_loss: 2.0867 - val_accuracy: 0.2906\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0759 - accuracy: 0.2952 - val_loss: 2.0432 - val_accuracy: 0.2882\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0376 - accuracy: 0.2914 - val_loss: 2.0031 - val_accuracy: 0.2942\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.9854 - accuracy: 0.3158 - val_loss: 1.9665 - val_accuracy: 0.2958\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9845 - accuracy: 0.3054 - val_loss: 1.9466 - val_accuracy: 0.2940\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9373 - accuracy: 0.3032 - val_loss: 1.8914 - val_accuracy: 0.2924\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8787 - accuracy: 0.3197 - val_loss: 1.8663 - val_accuracy: 0.2922\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8614 - accuracy: 0.3015 - val_loss: 1.8295 - val_accuracy: 0.2940\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8270 - accuracy: 0.2862 - val_loss: 1.9321 - val_accuracy: 0.2886\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8702 - accuracy: 0.3046 - val_loss: 1.7793 - val_accuracy: 0.2950\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7938 - accuracy: 0.3005 - val_loss: 1.7913 - val_accuracy: 0.2948\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7831 - accuracy: 0.2893 - val_loss: 1.8141 - val_accuracy: 0.2914\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7776 - accuracy: 0.2982 - val_loss: 1.7171 - val_accuracy: 0.2906\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7206 - accuracy: 0.3008 - val_loss: 1.7067 - val_accuracy: 0.2886\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6864 - accuracy: 0.3035 - val_loss: 1.6772 - val_accuracy: 0.2926\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6840 - accuracy: 0.2964 - val_loss: 1.6795 - val_accuracy: 0.2894\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6755 - accuracy: 0.2968 - val_loss: 1.6633 - val_accuracy: 0.2896\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6569 - accuracy: 0.3072 - val_loss: 1.6583 - val_accuracy: 0.2880\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6682 - accuracy: 0.3060 - val_loss: 1.6572 - val_accuracy: 0.2858\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6471 - accuracy: 0.2994 - val_loss: 1.6353 - val_accuracy: 0.2890\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6292 - accuracy: 0.2966 - val_loss: 1.6149 - val_accuracy: 0.2912\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6159 - accuracy: 0.2963 - val_loss: 1.6040 - val_accuracy: 0.2898\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6049 - accuracy: 0.3005 - val_loss: 1.5900 - val_accuracy: 0.2906\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5993 - accuracy: 0.2916 - val_loss: 1.5869 - val_accuracy: 0.2882\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5807 - accuracy: 0.2973 - val_loss: 1.5743 - val_accuracy: 0.2906\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6275 - accuracy: 0.3017 - val_loss: 1.5841 - val_accuracy: 0.2834\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6855 - accuracy: 0.2820 - val_loss: 1.5635 - val_accuracy: 0.2912\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5654 - accuracy: 0.2972 - val_loss: 1.5593 - val_accuracy: 0.2902\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7974 - accuracy: 0.2696 - val_loss: 1.6122 - val_accuracy: 0.2932\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8096 - accuracy: 0.2602 - val_loss: 2.0093 - val_accuracy: 0.2372\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0640 - accuracy: 0.2327 - val_loss: 1.7947 - val_accuracy: 0.2650\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7734 - accuracy: 0.2794 - val_loss: 1.7308 - val_accuracy: 0.2650\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7311 - accuracy: 0.2792 - val_loss: 1.7011 - val_accuracy: 0.2674\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7122 - accuracy: 0.2817 - val_loss: 1.7476 - val_accuracy: 0.2922\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7178 - accuracy: 0.3020 - val_loss: 1.6661 - val_accuracy: 0.2638\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6583 - accuracy: 0.2898 - val_loss: 1.6455 - val_accuracy: 0.2994\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6406 - accuracy: 0.2967 - val_loss: 1.6367 - val_accuracy: 0.3000\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6408 - accuracy: 0.3061 - val_loss: 1.6499 - val_accuracy: 0.2910\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7341 - accuracy: 0.2724 - val_loss: 1.8346 - val_accuracy: 0.2686\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7107 - accuracy: 0.2932 - val_loss: 1.6236 - val_accuracy: 0.2888\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6246 - accuracy: 0.3022 - val_loss: 1.5988 - val_accuracy: 0.2906\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6167 - accuracy: 0.2973 - val_loss: 1.7276 - val_accuracy: 0.2674\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6829 - accuracy: 0.2851 - val_loss: 1.5847 - val_accuracy: 0.2934\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5742 - accuracy: 0.3035 - val_loss: 1.5749 - val_accuracy: 0.2894\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5722 - accuracy: 0.3012 - val_loss: 1.5667 - val_accuracy: 0.2942\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5682 - accuracy: 0.3052 - val_loss: 1.5565 - val_accuracy: 0.2880\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5600 - accuracy: 0.2990 - val_loss: 1.5548 - val_accuracy: 0.2868\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3573 - accuracy: 0.1897 - val_loss: 1.8024 - val_accuracy: 0.2992\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7642 - accuracy: 0.3499 - val_loss: 1.5777 - val_accuracy: 0.4508\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6137 - accuracy: 0.4125 - val_loss: 1.5427 - val_accuracy: 0.4620\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5062 - accuracy: 0.4390 - val_loss: 1.6156 - val_accuracy: 0.3704\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4993 - accuracy: 0.4289 - val_loss: 1.3614 - val_accuracy: 0.5416\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3705 - accuracy: 0.5078 - val_loss: 1.2942 - val_accuracy: 0.5336\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3022 - accuracy: 0.5073 - val_loss: 1.2295 - val_accuracy: 0.4836\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2070 - accuracy: 0.5331 - val_loss: 1.1643 - val_accuracy: 0.5480\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1985 - accuracy: 0.5574 - val_loss: 1.2127 - val_accuracy: 0.4990\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1686 - accuracy: 0.5512 - val_loss: 1.0467 - val_accuracy: 0.6240\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0437 - accuracy: 0.6019 - val_loss: 1.0193 - val_accuracy: 0.6164\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0378 - accuracy: 0.6162 - val_loss: 1.0436 - val_accuracy: 0.5670\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0191 - accuracy: 0.5917 - val_loss: 0.9705 - val_accuracy: 0.6198\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9796 - accuracy: 0.6358 - val_loss: 0.9923 - val_accuracy: 0.6142\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9647 - accuracy: 0.6272 - val_loss: 0.8841 - val_accuracy: 0.6538\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9161 - accuracy: 0.6379 - val_loss: 0.8479 - val_accuracy: 0.6664\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8605 - accuracy: 0.6754 - val_loss: 0.9101 - val_accuracy: 0.6618\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8449 - accuracy: 0.6846 - val_loss: 0.8606 - val_accuracy: 0.6654\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.6675 - val_loss: 0.8253 - val_accuracy: 0.7040\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8373 - accuracy: 0.6585 - val_loss: 0.9171 - val_accuracy: 0.6276\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8609 - accuracy: 0.6639 - val_loss: 0.8964 - val_accuracy: 0.6656\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8990 - accuracy: 0.6712 - val_loss: 0.9215 - val_accuracy: 0.6594\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9366 - accuracy: 0.6531 - val_loss: 1.4194 - val_accuracy: 0.5384\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0353 - accuracy: 0.6149 - val_loss: 1.0011 - val_accuracy: 0.6620\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9836 - accuracy: 0.6473 - val_loss: 0.8562 - val_accuracy: 0.6678\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8007 - accuracy: 0.6913 - val_loss: 0.7953 - val_accuracy: 0.7136\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7649 - accuracy: 0.7112 - val_loss: 0.7577 - val_accuracy: 0.6966\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7884 - accuracy: 0.7155 - val_loss: 0.7579 - val_accuracy: 0.7034\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7649 - accuracy: 0.6996 - val_loss: 0.8253 - val_accuracy: 0.6844\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8259 - accuracy: 0.7043 - val_loss: 0.7697 - val_accuracy: 0.7058\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7384 - accuracy: 0.7241 - val_loss: 0.8463 - val_accuracy: 0.6696\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8037 - accuracy: 0.6917 - val_loss: 0.8291 - val_accuracy: 0.6982\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8420 - accuracy: 0.6916 - val_loss: 0.7637 - val_accuracy: 0.7240\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8040 - accuracy: 0.6960 - val_loss: 0.8055 - val_accuracy: 0.6962\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7898 - accuracy: 0.6862 - val_loss: 1.3128 - val_accuracy: 0.5812\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7985 - accuracy: 0.7157 - val_loss: 0.8519 - val_accuracy: 0.6906\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8823 - accuracy: 0.6731 - val_loss: 0.8380 - val_accuracy: 0.6824\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8259 - accuracy: 0.6794 - val_loss: 0.7719 - val_accuracy: 0.7176\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7946 - accuracy: 0.7089 - val_loss: 0.7349 - val_accuracy: 0.7042\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7236 - accuracy: 0.7249 - val_loss: 0.8379 - val_accuracy: 0.6928\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7446 - accuracy: 0.7309 - val_loss: 0.7225 - val_accuracy: 0.7400\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6808 - accuracy: 0.7447 - val_loss: 0.7717 - val_accuracy: 0.7194\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7747 - accuracy: 0.7172 - val_loss: 0.7773 - val_accuracy: 0.6988\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7674 - accuracy: 0.7069 - val_loss: 0.8011 - val_accuracy: 0.6970\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7790 - accuracy: 0.7082 - val_loss: 0.7737 - val_accuracy: 0.7152\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7556 - accuracy: 0.7091 - val_loss: 0.7836 - val_accuracy: 0.7158\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8073 - accuracy: 0.7150 - val_loss: 0.8105 - val_accuracy: 0.7082\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8076 - accuracy: 0.7305 - val_loss: 0.7962 - val_accuracy: 0.7114\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7448 - accuracy: 0.7340 - val_loss: 0.9564 - val_accuracy: 0.6878\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7858 - accuracy: 0.7109 - val_loss: 0.7758 - val_accuracy: 0.7084\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0961 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1080 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1041 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0905 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0970 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0934 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0929 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0939 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1016 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1035 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1048 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0938 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0959 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0931 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0954 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1054 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0932 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1034 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0922 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0920 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0915 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0931 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0929 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0414 - accuracy: 0.3065 - val_loss: 1.5054 - val_accuracy: 0.5542\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3584 - accuracy: 0.5944 - val_loss: 1.1530 - val_accuracy: 0.6516\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0816 - accuracy: 0.6691 - val_loss: 1.0179 - val_accuracy: 0.6404\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9716 - accuracy: 0.6730 - val_loss: 0.9010 - val_accuracy: 0.6758\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9010 - accuracy: 0.6794 - val_loss: 0.8841 - val_accuracy: 0.6846\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8534 - accuracy: 0.7130 - val_loss: 0.8777 - val_accuracy: 0.6818\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.7150 - val_loss: 0.8215 - val_accuracy: 0.7172\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8135 - accuracy: 0.7189 - val_loss: 0.8689 - val_accuracy: 0.6834\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8154 - accuracy: 0.7081 - val_loss: 0.8170 - val_accuracy: 0.7160\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7782 - accuracy: 0.7243 - val_loss: 0.7963 - val_accuracy: 0.7082\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7746 - accuracy: 0.7268 - val_loss: 0.7792 - val_accuracy: 0.7264\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7647 - accuracy: 0.7425 - val_loss: 0.7943 - val_accuracy: 0.7168\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7858 - accuracy: 0.7229 - val_loss: 0.7841 - val_accuracy: 0.7130\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7390 - accuracy: 0.7312 - val_loss: 0.8344 - val_accuracy: 0.6996\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7721 - accuracy: 0.7384 - val_loss: 0.8437 - val_accuracy: 0.6892\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8195 - accuracy: 0.7221 - val_loss: 0.7910 - val_accuracy: 0.7356\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8149 - accuracy: 0.7232 - val_loss: 0.9340 - val_accuracy: 0.6758\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8340 - accuracy: 0.7119 - val_loss: 0.7843 - val_accuracy: 0.7110\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7920 - accuracy: 0.7013 - val_loss: 0.8043 - val_accuracy: 0.7078\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7571 - accuracy: 0.7199 - val_loss: 0.8075 - val_accuracy: 0.6738\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7739 - accuracy: 0.7109 - val_loss: 0.8028 - val_accuracy: 0.7058\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8246 - accuracy: 0.7036 - val_loss: 0.7920 - val_accuracy: 0.7072\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7994 - accuracy: 0.7164 - val_loss: 0.7837 - val_accuracy: 0.7268\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7805 - accuracy: 0.7156 - val_loss: 0.8021 - val_accuracy: 0.7400\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7835 - accuracy: 0.7426 - val_loss: 0.8275 - val_accuracy: 0.6956\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7666 - accuracy: 0.7103 - val_loss: 0.9432 - val_accuracy: 0.6440\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8701 - accuracy: 0.6813 - val_loss: 0.9111 - val_accuracy: 0.6636\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8197 - accuracy: 0.6894 - val_loss: 0.7892 - val_accuracy: 0.6956\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7706 - accuracy: 0.7177 - val_loss: 0.7826 - val_accuracy: 0.7022\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7980 - accuracy: 0.6967 - val_loss: 0.9108 - val_accuracy: 0.6240\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8621 - accuracy: 0.6609 - val_loss: 0.8256 - val_accuracy: 0.7142\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8156 - accuracy: 0.6997 - val_loss: 0.7874 - val_accuracy: 0.7156\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7744 - accuracy: 0.7065 - val_loss: 0.8224 - val_accuracy: 0.6574\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8262 - accuracy: 0.6921 - val_loss: 0.8988 - val_accuracy: 0.6708\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8426 - accuracy: 0.6908 - val_loss: 0.8164 - val_accuracy: 0.6956\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8140 - accuracy: 0.7108 - val_loss: 0.8919 - val_accuracy: 0.6806\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8208 - accuracy: 0.6955 - val_loss: 0.8286 - val_accuracy: 0.6992\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7710 - accuracy: 0.7124 - val_loss: 0.8157 - val_accuracy: 0.6808\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8153 - accuracy: 0.6885 - val_loss: 0.9089 - val_accuracy: 0.6564\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8679 - accuracy: 0.6744 - val_loss: 0.9748 - val_accuracy: 0.6266\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9088 - accuracy: 0.6719 - val_loss: 0.9166 - val_accuracy: 0.6888\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8589 - accuracy: 0.6983 - val_loss: 0.8334 - val_accuracy: 0.6732\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8322 - accuracy: 0.6914 - val_loss: 0.7861 - val_accuracy: 0.7006\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8286 - accuracy: 0.6861 - val_loss: 0.9229 - val_accuracy: 0.6778\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8122 - accuracy: 0.6925 - val_loss: 0.7639 - val_accuracy: 0.6932\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7774 - accuracy: 0.6881 - val_loss: 0.8037 - val_accuracy: 0.6840\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7596 - accuracy: 0.7001 - val_loss: 0.7716 - val_accuracy: 0.6884\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7675 - accuracy: 0.7201 - val_loss: 0.7685 - val_accuracy: 0.7004\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7690 - accuracy: 0.7079 - val_loss: 0.8376 - val_accuracy: 0.6904\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7912 - accuracy: 0.7095 - val_loss: 0.8506 - val_accuracy: 0.6776\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3279 - accuracy: 0.2403 - val_loss: 2.0475 - val_accuracy: 0.5314\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.9830 - accuracy: 0.5686 - val_loss: 1.8337 - val_accuracy: 0.5746\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7855 - accuracy: 0.5998 - val_loss: 1.6538 - val_accuracy: 0.6214\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6030 - accuracy: 0.6619 - val_loss: 1.5004 - val_accuracy: 0.6206\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4624 - accuracy: 0.6433 - val_loss: 1.3573 - val_accuracy: 0.6614\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3181 - accuracy: 0.6774 - val_loss: 1.2536 - val_accuracy: 0.6546\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2259 - accuracy: 0.6831 - val_loss: 1.1700 - val_accuracy: 0.6742\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1219 - accuracy: 0.6975 - val_loss: 1.1013 - val_accuracy: 0.6850\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0781 - accuracy: 0.6943 - val_loss: 1.0627 - val_accuracy: 0.6876\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.7028 - val_loss: 0.9960 - val_accuracy: 0.7000\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9672 - accuracy: 0.7131 - val_loss: 0.9515 - val_accuracy: 0.7000\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9259 - accuracy: 0.7160 - val_loss: 0.9124 - val_accuracy: 0.7096\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8897 - accuracy: 0.7214 - val_loss: 0.8874 - val_accuracy: 0.7022\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8599 - accuracy: 0.7195 - val_loss: 0.8809 - val_accuracy: 0.7150\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8562 - accuracy: 0.7272 - val_loss: 0.8468 - val_accuracy: 0.7192\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8104 - accuracy: 0.7384 - val_loss: 0.8220 - val_accuracy: 0.7314\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7842 - accuracy: 0.7472 - val_loss: 0.8128 - val_accuracy: 0.7450\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8070 - accuracy: 0.7404 - val_loss: 0.7914 - val_accuracy: 0.7242\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7718 - accuracy: 0.7419 - val_loss: 0.7750 - val_accuracy: 0.7454\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7522 - accuracy: 0.7579 - val_loss: 0.7856 - val_accuracy: 0.7464\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7706 - accuracy: 0.7375 - val_loss: 0.7635 - val_accuracy: 0.7318\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7355 - accuracy: 0.7504 - val_loss: 0.7388 - val_accuracy: 0.7582\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7265 - accuracy: 0.7568 - val_loss: 0.7194 - val_accuracy: 0.7478\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7653 - val_loss: 0.7223 - val_accuracy: 0.7620\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7284 - accuracy: 0.7539 - val_loss: 0.7229 - val_accuracy: 0.7576\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6753 - accuracy: 0.7820 - val_loss: 0.7123 - val_accuracy: 0.7490\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6835 - accuracy: 0.7653 - val_loss: 0.7081 - val_accuracy: 0.7556\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6821 - accuracy: 0.7643 - val_loss: 0.7038 - val_accuracy: 0.7582\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.7801 - val_loss: 0.6823 - val_accuracy: 0.7574\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6272 - accuracy: 0.7956 - val_loss: 0.6731 - val_accuracy: 0.7864\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6487 - accuracy: 0.7903 - val_loss: 0.6844 - val_accuracy: 0.7768\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6511 - accuracy: 0.7885 - val_loss: 0.6948 - val_accuracy: 0.7582\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6559 - accuracy: 0.7754 - val_loss: 0.6694 - val_accuracy: 0.7780\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.7871 - val_loss: 0.6854 - val_accuracy: 0.7764\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6499 - accuracy: 0.7904 - val_loss: 0.6582 - val_accuracy: 0.7820\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.7926 - val_loss: 0.6557 - val_accuracy: 0.7818\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.7929 - val_loss: 0.6477 - val_accuracy: 0.7758\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.7949 - val_loss: 0.6609 - val_accuracy: 0.7664\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.7976 - val_loss: 0.6412 - val_accuracy: 0.7816\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5998 - accuracy: 0.7986 - val_loss: 0.6439 - val_accuracy: 0.7810\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6160 - accuracy: 0.7955 - val_loss: 0.6425 - val_accuracy: 0.7828\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.7797 - val_loss: 0.6604 - val_accuracy: 0.7550\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.7858 - val_loss: 0.6357 - val_accuracy: 0.7876\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6335 - accuracy: 0.7926 - val_loss: 0.6495 - val_accuracy: 0.7916\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5903 - accuracy: 0.8110 - val_loss: 0.6201 - val_accuracy: 0.7924\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.7969 - val_loss: 0.6227 - val_accuracy: 0.7858\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5762 - accuracy: 0.8022 - val_loss: 0.6211 - val_accuracy: 0.7650\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5841 - accuracy: 0.7936 - val_loss: 0.6292 - val_accuracy: 0.7860\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.7877 - val_loss: 0.6231 - val_accuracy: 0.7670\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.5886 - accuracy: 0.8007 - val_loss: 0.6593 - val_accuracy: 0.7726\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3022 - accuracy: 0.0850 - val_loss: 2.3008 - val_accuracy: 0.1248\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2995 - accuracy: 0.1432 - val_loss: 2.2994 - val_accuracy: 0.1574\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2978 - accuracy: 0.1651 - val_loss: 2.2980 - val_accuracy: 0.1652\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2959 - accuracy: 0.1714 - val_loss: 2.2968 - val_accuracy: 0.1526\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2943 - accuracy: 0.1740 - val_loss: 2.2956 - val_accuracy: 0.1558\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2927 - accuracy: 0.1950 - val_loss: 2.2945 - val_accuracy: 0.1440\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2918 - accuracy: 0.1426 - val_loss: 2.2932 - val_accuracy: 0.1632\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2895 - accuracy: 0.1666 - val_loss: 2.2917 - val_accuracy: 0.1754\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2885 - accuracy: 0.1912 - val_loss: 2.2902 - val_accuracy: 0.1892\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2858 - accuracy: 0.1766 - val_loss: 2.2884 - val_accuracy: 0.2054\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2829 - accuracy: 0.2356 - val_loss: 2.2860 - val_accuracy: 0.2160\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2819 - accuracy: 0.2204 - val_loss: 2.2832 - val_accuracy: 0.2230\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2781 - accuracy: 0.2412 - val_loss: 2.2796 - val_accuracy: 0.2266\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2735 - accuracy: 0.2557 - val_loss: 2.2745 - val_accuracy: 0.2412\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2669 - accuracy: 0.2548 - val_loss: 2.2662 - val_accuracy: 0.3076\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2589 - accuracy: 0.3291 - val_loss: 2.2509 - val_accuracy: 0.3088\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2412 - accuracy: 0.3164 - val_loss: 2.2238 - val_accuracy: 0.2882\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2133 - accuracy: 0.2897 - val_loss: 2.1918 - val_accuracy: 0.2766\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1804 - accuracy: 0.2860 - val_loss: 2.1569 - val_accuracy: 0.2830\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1442 - accuracy: 0.3015 - val_loss: 2.1180 - val_accuracy: 0.2994\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0999 - accuracy: 0.3254 - val_loss: 2.0705 - val_accuracy: 0.3684\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0536 - accuracy: 0.3866 - val_loss: 2.0179 - val_accuracy: 0.3726\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.9933 - accuracy: 0.3943 - val_loss: 1.9653 - val_accuracy: 0.3750\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.9452 - accuracy: 0.3921 - val_loss: 1.9141 - val_accuracy: 0.3804\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.8937 - accuracy: 0.3960 - val_loss: 1.8668 - val_accuracy: 0.4134\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.8526 - accuracy: 0.4087 - val_loss: 1.8211 - val_accuracy: 0.3970\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8013 - accuracy: 0.4047 - val_loss: 1.7823 - val_accuracy: 0.3964\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7599 - accuracy: 0.4016 - val_loss: 1.7426 - val_accuracy: 0.3962\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7266 - accuracy: 0.4056 - val_loss: 1.7121 - val_accuracy: 0.3948\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6795 - accuracy: 0.4118 - val_loss: 1.6732 - val_accuracy: 0.3948\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6592 - accuracy: 0.3996 - val_loss: 1.6450 - val_accuracy: 0.3966\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6235 - accuracy: 0.4146 - val_loss: 1.6193 - val_accuracy: 0.3946\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5948 - accuracy: 0.4156 - val_loss: 1.5927 - val_accuracy: 0.3972\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5772 - accuracy: 0.4106 - val_loss: 1.5728 - val_accuracy: 0.3968\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5633 - accuracy: 0.4011 - val_loss: 1.5444 - val_accuracy: 0.3982\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5326 - accuracy: 0.4113 - val_loss: 1.5268 - val_accuracy: 0.3980\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5075 - accuracy: 0.4211 - val_loss: 1.5090 - val_accuracy: 0.4030\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4957 - accuracy: 0.3988 - val_loss: 1.4853 - val_accuracy: 0.4000\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4693 - accuracy: 0.4064 - val_loss: 1.4831 - val_accuracy: 0.4100\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4655 - accuracy: 0.4108 - val_loss: 1.4672 - val_accuracy: 0.4042\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4510 - accuracy: 0.4208 - val_loss: 1.4587 - val_accuracy: 0.4094\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4306 - accuracy: 0.4262 - val_loss: 1.4398 - val_accuracy: 0.4090\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4317 - accuracy: 0.4134 - val_loss: 1.4389 - val_accuracy: 0.4066\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4063 - accuracy: 0.4207 - val_loss: 1.4150 - val_accuracy: 0.4078\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4066 - accuracy: 0.4145 - val_loss: 1.4238 - val_accuracy: 0.4088\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3962 - accuracy: 0.4126 - val_loss: 1.4009 - val_accuracy: 0.4142\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3675 - accuracy: 0.4344 - val_loss: 1.3873 - val_accuracy: 0.4146\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3563 - accuracy: 0.4413 - val_loss: 1.3759 - val_accuracy: 0.4108\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3588 - accuracy: 0.4207 - val_loss: 1.3657 - val_accuracy: 0.4158\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3434 - accuracy: 0.4291 - val_loss: 1.3566 - val_accuracy: 0.4284\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9259 - accuracy: 0.3547 - val_loss: 1.3318 - val_accuracy: 0.5576\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2237 - accuracy: 0.6287 - val_loss: 1.0754 - val_accuracy: 0.6404\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9866 - accuracy: 0.6819 - val_loss: 0.9115 - val_accuracy: 0.6702\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9029 - accuracy: 0.6871 - val_loss: 0.8553 - val_accuracy: 0.6882\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8456 - accuracy: 0.7002 - val_loss: 0.8445 - val_accuracy: 0.6932\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8360 - accuracy: 0.6981 - val_loss: 0.8059 - val_accuracy: 0.6960\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7939 - accuracy: 0.7155 - val_loss: 0.8188 - val_accuracy: 0.7222\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7685 - accuracy: 0.7220 - val_loss: 0.7459 - val_accuracy: 0.7342\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7561 - accuracy: 0.7296 - val_loss: 0.7559 - val_accuracy: 0.7248\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7620 - accuracy: 0.7127 - val_loss: 0.7868 - val_accuracy: 0.7138\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7498 - accuracy: 0.7293 - val_loss: 0.7581 - val_accuracy: 0.7154\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7370 - accuracy: 0.7399 - val_loss: 0.7440 - val_accuracy: 0.7332\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7147 - accuracy: 0.7371 - val_loss: 0.7346 - val_accuracy: 0.7072\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7104 - accuracy: 0.7428 - val_loss: 0.7672 - val_accuracy: 0.7028\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7441 - accuracy: 0.7230 - val_loss: 0.7593 - val_accuracy: 0.7206\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7575 - val_loss: 0.7554 - val_accuracy: 0.7230\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7123 - accuracy: 0.7400 - val_loss: 0.7493 - val_accuracy: 0.7336\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7560 - accuracy: 0.7263 - val_loss: 0.8046 - val_accuracy: 0.7410\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7479 - accuracy: 0.7412 - val_loss: 0.7329 - val_accuracy: 0.7508\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7308 - accuracy: 0.7376 - val_loss: 0.7457 - val_accuracy: 0.7330\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7212 - accuracy: 0.7458 - val_loss: 0.7679 - val_accuracy: 0.7428\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7301 - accuracy: 0.7479 - val_loss: 0.7552 - val_accuracy: 0.7022\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7279 - accuracy: 0.7529 - val_loss: 0.7404 - val_accuracy: 0.7454\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7171 - accuracy: 0.7361 - val_loss: 0.7759 - val_accuracy: 0.7074\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7283 - accuracy: 0.7334 - val_loss: 0.8148 - val_accuracy: 0.6934\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7504 - accuracy: 0.7154 - val_loss: 0.8398 - val_accuracy: 0.6886\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7782 - accuracy: 0.7245 - val_loss: 0.7266 - val_accuracy: 0.7424\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7283 - accuracy: 0.7425 - val_loss: 0.7002 - val_accuracy: 0.7498\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.6667 - accuracy: 0.7684 - val_loss: 0.7223 - val_accuracy: 0.7362\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7142 - accuracy: 0.7415 - val_loss: 0.7421 - val_accuracy: 0.7268\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7300 - accuracy: 0.7364 - val_loss: 0.9249 - val_accuracy: 0.6526\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8028 - accuracy: 0.7209 - val_loss: 0.7864 - val_accuracy: 0.7202\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7767 - accuracy: 0.7249 - val_loss: 0.7640 - val_accuracy: 0.7240\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7890 - accuracy: 0.7153 - val_loss: 0.7652 - val_accuracy: 0.7150\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7570 - accuracy: 0.7304 - val_loss: 0.7706 - val_accuracy: 0.7048\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7352 - accuracy: 0.7302 - val_loss: 0.7746 - val_accuracy: 0.6916\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7349 - accuracy: 0.7288 - val_loss: 0.7447 - val_accuracy: 0.7192\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7601 - accuracy: 0.7274 - val_loss: 0.7629 - val_accuracy: 0.6992\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7839 - accuracy: 0.7166 - val_loss: 0.8104 - val_accuracy: 0.6836\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8240 - accuracy: 0.6926 - val_loss: 0.7893 - val_accuracy: 0.7304\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7867 - accuracy: 0.7220 - val_loss: 0.8722 - val_accuracy: 0.6728\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7915 - accuracy: 0.7224 - val_loss: 0.8729 - val_accuracy: 0.6924\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8434 - accuracy: 0.6908 - val_loss: 0.8177 - val_accuracy: 0.6786\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8117 - accuracy: 0.6870 - val_loss: 0.7971 - val_accuracy: 0.7256\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7792 - accuracy: 0.7132 - val_loss: 0.7800 - val_accuracy: 0.7296\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7440 - accuracy: 0.7280 - val_loss: 0.7988 - val_accuracy: 0.7266\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7658 - accuracy: 0.7244 - val_loss: 0.7742 - val_accuracy: 0.7082\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7724 - accuracy: 0.7129 - val_loss: 0.7658 - val_accuracy: 0.7162\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7694 - accuracy: 0.7052 - val_loss: 0.7761 - val_accuracy: 0.7072\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7980 - accuracy: 0.7020 - val_loss: 0.7885 - val_accuracy: 0.7192\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.7668 - accuracy: 0.3911 - val_loss: 1.4006 - val_accuracy: 0.4716\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1531 - accuracy: 0.5555 - val_loss: 1.0188 - val_accuracy: 0.6290\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1145 - accuracy: 0.5692 - val_loss: 1.6704 - val_accuracy: 0.4090\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0999 - accuracy: 0.5687 - val_loss: 1.2817 - val_accuracy: 0.5012\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1621 - accuracy: 0.5504 - val_loss: 1.4894 - val_accuracy: 0.3712\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2311 - accuracy: 0.5138 - val_loss: 1.1154 - val_accuracy: 0.5974\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1543 - accuracy: 0.5336 - val_loss: 1.4735 - val_accuracy: 0.3634\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2088 - accuracy: 0.5177 - val_loss: 1.4853 - val_accuracy: 0.4376\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0952 - accuracy: 0.5534 - val_loss: 1.9020 - val_accuracy: 0.3308\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1946 - accuracy: 0.5242 - val_loss: 1.2993 - val_accuracy: 0.4142\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1903 - accuracy: 0.5221 - val_loss: 2.0523 - val_accuracy: 0.2304\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3215 - accuracy: 0.4749 - val_loss: 1.6514 - val_accuracy: 0.2964\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2965 - accuracy: 0.4769 - val_loss: 1.7904 - val_accuracy: 0.3002\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2890 - accuracy: 0.4822 - val_loss: 2.2982 - val_accuracy: 0.2788\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2495 - accuracy: 0.5106 - val_loss: 1.1416 - val_accuracy: 0.5514\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2466 - accuracy: 0.5103 - val_loss: 1.3796 - val_accuracy: 0.4538\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3919 - accuracy: 0.4329 - val_loss: 1.7796 - val_accuracy: 0.2482\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5070 - accuracy: 0.3853 - val_loss: 2.3343 - val_accuracy: 0.2058\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7563 - accuracy: 0.3433 - val_loss: 1.4020 - val_accuracy: 0.4570\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5089 - accuracy: 0.3900 - val_loss: 1.8626 - val_accuracy: 0.2742\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4042 - accuracy: 0.4242 - val_loss: 1.6093 - val_accuracy: 0.4164\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3684 - accuracy: 0.4148 - val_loss: 1.8568 - val_accuracy: 0.3918\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4879 - accuracy: 0.4032 - val_loss: 1.6179 - val_accuracy: 0.3786\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3745 - accuracy: 0.4183 - val_loss: 1.9391 - val_accuracy: 0.3460\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6223 - accuracy: 0.3476 - val_loss: 1.6188 - val_accuracy: 0.3044\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5359 - accuracy: 0.3702 - val_loss: 1.6617 - val_accuracy: 0.3106\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5525 - accuracy: 0.3695 - val_loss: 1.4404 - val_accuracy: 0.3570\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3125 - accuracy: 0.4826 - val_loss: 1.4177 - val_accuracy: 0.4222\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3361 - accuracy: 0.4388 - val_loss: 1.4595 - val_accuracy: 0.4512\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4197 - accuracy: 0.4148 - val_loss: 1.3209 - val_accuracy: 0.4758\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2187 - accuracy: 0.4894 - val_loss: 1.3005 - val_accuracy: 0.3966\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1851 - accuracy: 0.4970 - val_loss: 1.4145 - val_accuracy: 0.3948\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2485 - accuracy: 0.4751 - val_loss: 1.3021 - val_accuracy: 0.4746\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1679 - accuracy: 0.5171 - val_loss: 1.3432 - val_accuracy: 0.4470\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2895 - accuracy: 0.4607 - val_loss: 1.3456 - val_accuracy: 0.5294\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3084 - accuracy: 0.4730 - val_loss: 1.5072 - val_accuracy: 0.3686\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4142 - accuracy: 0.3917 - val_loss: 1.4120 - val_accuracy: 0.3770\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3992 - accuracy: 0.3870 - val_loss: 1.3697 - val_accuracy: 0.4274\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2689 - accuracy: 0.4507 - val_loss: 1.2659 - val_accuracy: 0.5390\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1525 - accuracy: 0.5321 - val_loss: 1.5348 - val_accuracy: 0.3998\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2064 - accuracy: 0.4783 - val_loss: 1.3043 - val_accuracy: 0.3792\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1744 - accuracy: 0.4989 - val_loss: 1.2203 - val_accuracy: 0.4994\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0605 - accuracy: 0.5665 - val_loss: 1.5025 - val_accuracy: 0.4758\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0648 - accuracy: 0.6087 - val_loss: 1.1568 - val_accuracy: 0.5484\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1983 - accuracy: 0.5009 - val_loss: 1.3921 - val_accuracy: 0.4556\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2289 - accuracy: 0.4859 - val_loss: 1.8390 - val_accuracy: 0.3926\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3621 - accuracy: 0.4450 - val_loss: 1.5133 - val_accuracy: 0.3836\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4361 - accuracy: 0.4540 - val_loss: 1.3643 - val_accuracy: 0.4856\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1687 - accuracy: 0.5358 - val_loss: 1.2496 - val_accuracy: 0.5970\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0983 - accuracy: 0.5679 - val_loss: 1.2880 - val_accuracy: 0.4634\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3088 - accuracy: 0.1226 - val_loss: 2.2701 - val_accuracy: 0.1084\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2570 - accuracy: 0.1705 - val_loss: 2.1999 - val_accuracy: 0.3144\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1888 - accuracy: 0.3158 - val_loss: 2.1503 - val_accuracy: 0.3220\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1336 - accuracy: 0.3369 - val_loss: 2.2748 - val_accuracy: 0.1954\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1181 - accuracy: 0.2611 - val_loss: 1.9856 - val_accuracy: 0.2998\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9567 - accuracy: 0.3275 - val_loss: 1.9333 - val_accuracy: 0.2820\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8917 - accuracy: 0.3233 - val_loss: 1.8223 - val_accuracy: 0.3138\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8169 - accuracy: 0.3303 - val_loss: 1.8913 - val_accuracy: 0.2350\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8336 - accuracy: 0.2664 - val_loss: 1.7434 - val_accuracy: 0.2724\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7790 - accuracy: 0.2830 - val_loss: 1.6927 - val_accuracy: 0.2742\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7341 - accuracy: 0.2775 - val_loss: 2.2697 - val_accuracy: 0.1708\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1809 - accuracy: 0.1970 - val_loss: 1.9503 - val_accuracy: 0.2324\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7994 - accuracy: 0.2701 - val_loss: 1.6383 - val_accuracy: 0.2870\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6579 - accuracy: 0.2866 - val_loss: 1.6558 - val_accuracy: 0.2742\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6540 - accuracy: 0.2747 - val_loss: 1.5774 - val_accuracy: 0.2870\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7007 - accuracy: 0.2693 - val_loss: 1.9106 - val_accuracy: 0.2160\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8532 - accuracy: 0.2281 - val_loss: 1.6382 - val_accuracy: 0.2802\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5904 - accuracy: 0.2868 - val_loss: 1.5877 - val_accuracy: 0.2938\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5687 - accuracy: 0.2938 - val_loss: 1.5993 - val_accuracy: 0.2774\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5998 - accuracy: 0.2852 - val_loss: 1.5833 - val_accuracy: 0.2728\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6697 - accuracy: 0.2787 - val_loss: 1.5413 - val_accuracy: 0.2944\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5630 - accuracy: 0.3016 - val_loss: 1.5335 - val_accuracy: 0.2904\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7133 - accuracy: 0.2418 - val_loss: 1.7444 - val_accuracy: 0.2022\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7409 - accuracy: 0.2202 - val_loss: 1.6074 - val_accuracy: 0.2852\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6387 - accuracy: 0.2842 - val_loss: 1.6696 - val_accuracy: 0.2920\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6773 - accuracy: 0.3036 - val_loss: 1.5868 - val_accuracy: 0.2892\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5820 - accuracy: 0.3000 - val_loss: 1.5502 - val_accuracy: 0.2992\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5403 - accuracy: 0.2960 - val_loss: 1.5434 - val_accuracy: 0.2964\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5784 - accuracy: 0.2992 - val_loss: 1.5186 - val_accuracy: 0.2946\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5945 - accuracy: 0.2879 - val_loss: 1.5145 - val_accuracy: 0.2914\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5283 - accuracy: 0.2981 - val_loss: 1.5034 - val_accuracy: 0.2914\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5189 - accuracy: 0.2966 - val_loss: 1.6590 - val_accuracy: 0.2632\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5844 - accuracy: 0.2873 - val_loss: 1.4934 - val_accuracy: 0.2974\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6117 - accuracy: 0.3026 - val_loss: 2.3840 - val_accuracy: 0.2112\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0964 - accuracy: 0.2457 - val_loss: 1.7792 - val_accuracy: 0.2772\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6656 - accuracy: 0.2907 - val_loss: 1.5516 - val_accuracy: 0.3004\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.5659 - accuracy: 0.2998 - val_loss: 1.5512 - val_accuracy: 0.2996\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5520 - accuracy: 0.2998 - val_loss: 1.5297 - val_accuracy: 0.3012\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5418 - accuracy: 0.3068 - val_loss: 1.5938 - val_accuracy: 0.2918\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6198 - accuracy: 0.2893 - val_loss: 1.5409 - val_accuracy: 0.2878\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5534 - accuracy: 0.2937 - val_loss: 1.5405 - val_accuracy: 0.2880\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5453 - accuracy: 0.3043 - val_loss: 1.5638 - val_accuracy: 0.2828\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5567 - accuracy: 0.2797 - val_loss: 1.5122 - val_accuracy: 0.2916\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5255 - accuracy: 0.3127 - val_loss: 1.5049 - val_accuracy: 0.2924\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5275 - accuracy: 0.3013 - val_loss: 1.5458 - val_accuracy: 0.2914\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5766 - accuracy: 0.2976 - val_loss: 1.5096 - val_accuracy: 0.2928\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5241 - accuracy: 0.3023 - val_loss: 1.5063 - val_accuracy: 0.3002\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5244 - accuracy: 0.3013 - val_loss: 1.5053 - val_accuracy: 0.2928\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5342 - accuracy: 0.2962 - val_loss: 1.4982 - val_accuracy: 0.2922\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5217 - accuracy: 0.3017 - val_loss: 1.5088 - val_accuracy: 0.3006\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3627 - accuracy: 0.0784 - val_loss: 2.2897 - val_accuracy: 0.1400\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2817 - accuracy: 0.1540 - val_loss: 2.2743 - val_accuracy: 0.2274\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2697 - accuracy: 0.2100 - val_loss: 2.2694 - val_accuracy: 0.2338\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2574 - accuracy: 0.2378 - val_loss: 2.2457 - val_accuracy: 0.2796\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2439 - accuracy: 0.2683 - val_loss: 2.2347 - val_accuracy: 0.3150\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2282 - accuracy: 0.3454 - val_loss: 2.2173 - val_accuracy: 0.3912\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2098 - accuracy: 0.3905 - val_loss: 2.1997 - val_accuracy: 0.3988\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1935 - accuracy: 0.4232 - val_loss: 2.1872 - val_accuracy: 0.4208\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1822 - accuracy: 0.4072 - val_loss: 2.1706 - val_accuracy: 0.4302\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1618 - accuracy: 0.4263 - val_loss: 2.1547 - val_accuracy: 0.3806\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1393 - accuracy: 0.4282 - val_loss: 2.1220 - val_accuracy: 0.4376\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1171 - accuracy: 0.4428 - val_loss: 2.0992 - val_accuracy: 0.4538\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0971 - accuracy: 0.4338 - val_loss: 2.0838 - val_accuracy: 0.4496\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0769 - accuracy: 0.4331 - val_loss: 2.0588 - val_accuracy: 0.4172\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0580 - accuracy: 0.4129 - val_loss: 2.1845 - val_accuracy: 0.2756\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1119 - accuracy: 0.3359 - val_loss: 2.0494 - val_accuracy: 0.3698\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0436 - accuracy: 0.3830 - val_loss: 2.0229 - val_accuracy: 0.3774\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0195 - accuracy: 0.3758 - val_loss: 1.9998 - val_accuracy: 0.3802\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.0243 - accuracy: 0.3291 - val_loss: 1.9817 - val_accuracy: 0.3572\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9721 - accuracy: 0.3639 - val_loss: 1.9474 - val_accuracy: 0.3768\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9367 - accuracy: 0.3785 - val_loss: 1.9114 - val_accuracy: 0.3694\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9387 - accuracy: 0.3397 - val_loss: 1.8874 - val_accuracy: 0.3808\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8713 - accuracy: 0.3957 - val_loss: 1.8731 - val_accuracy: 0.3690\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8776 - accuracy: 0.3692 - val_loss: 1.8338 - val_accuracy: 0.3724\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8366 - accuracy: 0.3613 - val_loss: 1.8035 - val_accuracy: 0.3848\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7971 - accuracy: 0.3861 - val_loss: 1.7793 - val_accuracy: 0.3844\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7595 - accuracy: 0.3958 - val_loss: 1.7365 - val_accuracy: 0.3888\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7505 - accuracy: 0.3704 - val_loss: 1.7193 - val_accuracy: 0.3694\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7214 - accuracy: 0.3770 - val_loss: 1.7027 - val_accuracy: 0.3760\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6813 - accuracy: 0.3843 - val_loss: 1.6608 - val_accuracy: 0.3812\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6730 - accuracy: 0.3695 - val_loss: 1.6349 - val_accuracy: 0.3730\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6664 - accuracy: 0.3608 - val_loss: 1.6267 - val_accuracy: 0.3752\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6419 - accuracy: 0.3782 - val_loss: 1.7068 - val_accuracy: 0.3596\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6480 - accuracy: 0.3760 - val_loss: 1.5727 - val_accuracy: 0.3876\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5765 - accuracy: 0.3847 - val_loss: 1.9004 - val_accuracy: 0.2718\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6644 - accuracy: 0.3536 - val_loss: 1.6406 - val_accuracy: 0.3488\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6277 - accuracy: 0.3518 - val_loss: 1.5843 - val_accuracy: 0.3474\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6306 - accuracy: 0.3356 - val_loss: 1.5174 - val_accuracy: 0.3822\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5243 - accuracy: 0.3751 - val_loss: 1.5122 - val_accuracy: 0.3744\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5309 - accuracy: 0.3679 - val_loss: 1.4981 - val_accuracy: 0.3854\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4930 - accuracy: 0.3815 - val_loss: 1.4962 - val_accuracy: 0.3698\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5027 - accuracy: 0.3540 - val_loss: 1.4602 - val_accuracy: 0.3774\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4591 - accuracy: 0.3857 - val_loss: 1.4488 - val_accuracy: 0.3752\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4616 - accuracy: 0.3780 - val_loss: 1.4517 - val_accuracy: 0.3648\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4658 - accuracy: 0.3694 - val_loss: 1.4101 - val_accuracy: 0.3890\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4288 - accuracy: 0.3959 - val_loss: 1.4524 - val_accuracy: 0.3758\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4424 - accuracy: 0.3832 - val_loss: 1.4224 - val_accuracy: 0.3826\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4998 - accuracy: 0.3605 - val_loss: 1.4495 - val_accuracy: 0.3670\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4415 - accuracy: 0.3802 - val_loss: 1.4363 - val_accuracy: 0.3688\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4415 - accuracy: 0.3621 - val_loss: 1.4182 - val_accuracy: 0.3610\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.3026 - accuracy: 0.1032 - val_loss: 2.3031 - val_accuracy: 0.0960\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3020 - accuracy: 0.1024 - val_loss: 2.3032 - val_accuracy: 0.0960\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3018 - accuracy: 0.1176 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3017 - accuracy: 0.1056 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3008 - accuracy: 0.1025 - val_loss: 2.3035 - val_accuracy: 0.0960\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3008 - accuracy: 0.1070 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.0997 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1029 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3001 - accuracy: 0.1028 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2997 - accuracy: 0.1090 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3015 - accuracy: 0.1050 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.1092 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.1095 - val_loss: 2.3038 - val_accuracy: 0.0960\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2994 - accuracy: 0.1096 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3010 - accuracy: 0.1075 - val_loss: 2.3038 - val_accuracy: 0.0960\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.1020 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3001 - accuracy: 0.1057 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2994 - accuracy: 0.1062 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3012 - accuracy: 0.1010 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3007 - accuracy: 0.1064 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3011 - accuracy: 0.1060 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2990 - accuracy: 0.1111 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2990 - accuracy: 0.1168 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2985 - accuracy: 0.1060 - val_loss: 2.3035 - val_accuracy: 0.0960\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2989 - accuracy: 0.1180 - val_loss: 2.3035 - val_accuracy: 0.0960\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2990 - accuracy: 0.1079 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2993 - accuracy: 0.1038 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2995 - accuracy: 0.1118 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2988 - accuracy: 0.1107 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3002 - accuracy: 0.1073 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2997 - accuracy: 0.1042 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2986 - accuracy: 0.1146 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2982 - accuracy: 0.1093 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2998 - accuracy: 0.1065 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2987 - accuracy: 0.1102 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2986 - accuracy: 0.1118 - val_loss: 2.3032 - val_accuracy: 0.0960\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2986 - accuracy: 0.1073 - val_loss: 2.3032 - val_accuracy: 0.0960\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2991 - accuracy: 0.1135 - val_loss: 2.3032 - val_accuracy: 0.0960\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2991 - accuracy: 0.1083 - val_loss: 2.3031 - val_accuracy: 0.0960\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2996 - accuracy: 0.1120 - val_loss: 2.3031 - val_accuracy: 0.0960\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3000 - accuracy: 0.1083 - val_loss: 2.3031 - val_accuracy: 0.0960\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2996 - accuracy: 0.1093 - val_loss: 2.3030 - val_accuracy: 0.0960\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2994 - accuracy: 0.1103 - val_loss: 2.3030 - val_accuracy: 0.0960\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2988 - accuracy: 0.1063 - val_loss: 2.3030 - val_accuracy: 0.0960\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2988 - accuracy: 0.1075 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1068 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2981 - accuracy: 0.1110 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2985 - accuracy: 0.1094 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2979 - accuracy: 0.1031 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2736 - accuracy: 0.1161 - val_loss: 2.1769 - val_accuracy: 0.1952\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.1578 - accuracy: 0.2670 - val_loss: 2.0556 - val_accuracy: 0.3054\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0163 - accuracy: 0.3018 - val_loss: 1.9378 - val_accuracy: 0.3378\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9028 - accuracy: 0.3175 - val_loss: 1.8065 - val_accuracy: 0.3000\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7786 - accuracy: 0.3033 - val_loss: 1.7072 - val_accuracy: 0.3062\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6868 - accuracy: 0.3065 - val_loss: 1.6628 - val_accuracy: 0.3198\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6889 - accuracy: 0.3171 - val_loss: 2.0784 - val_accuracy: 0.1850\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0179 - accuracy: 0.2019 - val_loss: 1.7728 - val_accuracy: 0.2844\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7593 - accuracy: 0.2857 - val_loss: 1.7087 - val_accuracy: 0.2554\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6665 - accuracy: 0.2951 - val_loss: 1.7864 - val_accuracy: 0.2898\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7581 - accuracy: 0.2779 - val_loss: 1.5979 - val_accuracy: 0.2982\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6446 - accuracy: 0.2964 - val_loss: 2.0540 - val_accuracy: 0.1986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9242 - accuracy: 0.2074 - val_loss: 1.8053 - val_accuracy: 0.2028\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8010 - accuracy: 0.2035 - val_loss: 1.8427 - val_accuracy: 0.2022\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8569 - accuracy: 0.2033 - val_loss: 1.8384 - val_accuracy: 0.2006\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8131 - accuracy: 0.2066 - val_loss: 1.7794 - val_accuracy: 0.2008\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7891 - accuracy: 0.2067 - val_loss: 1.7784 - val_accuracy: 0.2010\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7927 - accuracy: 0.2055 - val_loss: 1.7571 - val_accuracy: 0.2018\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7655 - accuracy: 0.2152 - val_loss: 1.7536 - val_accuracy: 0.2012\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7617 - accuracy: 0.2145 - val_loss: 1.7505 - val_accuracy: 0.2012\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7546 - accuracy: 0.2146 - val_loss: 1.7484 - val_accuracy: 0.2012\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7623 - accuracy: 0.2140 - val_loss: 1.7467 - val_accuracy: 0.2012\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7559 - accuracy: 0.2051 - val_loss: 1.7457 - val_accuracy: 0.2012\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7551 - accuracy: 0.2071 - val_loss: 1.7445 - val_accuracy: 0.2012\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7475 - accuracy: 0.2103 - val_loss: 1.7433 - val_accuracy: 0.2012\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7551 - accuracy: 0.2059 - val_loss: 1.7424 - val_accuracy: 0.2012\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7479 - accuracy: 0.2133 - val_loss: 1.7419 - val_accuracy: 0.2012\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7604 - accuracy: 0.1925 - val_loss: 1.7414 - val_accuracy: 0.2012\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7493 - accuracy: 0.2052 - val_loss: 1.7408 - val_accuracy: 0.2012\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7456 - accuracy: 0.2120 - val_loss: 1.7403 - val_accuracy: 0.2012\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7438 - accuracy: 0.2070 - val_loss: 1.7396 - val_accuracy: 0.2012\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7536 - accuracy: 0.2193 - val_loss: 1.7390 - val_accuracy: 0.2084\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7412 - accuracy: 0.2043 - val_loss: 1.7394 - val_accuracy: 0.2012\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7486 - accuracy: 0.2069 - val_loss: 1.7392 - val_accuracy: 0.2012\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7449 - accuracy: 0.2091 - val_loss: 1.7379 - val_accuracy: 0.2014\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7517 - accuracy: 0.2043 - val_loss: 1.7379 - val_accuracy: 0.2014\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7485 - accuracy: 0.2025 - val_loss: 1.7387 - val_accuracy: 0.2014\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7452 - accuracy: 0.2151 - val_loss: 1.7374 - val_accuracy: 0.2014\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7434 - accuracy: 0.1948 - val_loss: 1.7373 - val_accuracy: 0.2016\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7544 - accuracy: 0.2036 - val_loss: 1.7372 - val_accuracy: 0.2016\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7418 - accuracy: 0.2079 - val_loss: 1.7372 - val_accuracy: 0.2016\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7431 - accuracy: 0.2167 - val_loss: 1.7479 - val_accuracy: 0.2012\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7943 - accuracy: 0.2004 - val_loss: 1.7855 - val_accuracy: 0.2004\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7807 - accuracy: 0.2146 - val_loss: 1.8068 - val_accuracy: 0.1984\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7900 - accuracy: 0.2086 - val_loss: 1.7408 - val_accuracy: 0.2018\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7464 - accuracy: 0.2196 - val_loss: 1.7332 - val_accuracy: 0.2014\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7357 - accuracy: 0.2161 - val_loss: 1.7277 - val_accuracy: 0.2000\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7487 - accuracy: 0.2069 - val_loss: 1.7553 - val_accuracy: 0.2008\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7641 - accuracy: 0.2060 - val_loss: 1.7319 - val_accuracy: 0.2010\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7498 - accuracy: 0.2020 - val_loss: 1.7282 - val_accuracy: 0.2008\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.4499 - accuracy: 0.1186 - val_loss: 2.2311 - val_accuracy: 0.1226\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1669 - accuracy: 0.2135 - val_loss: 2.0754 - val_accuracy: 0.2740\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0214 - accuracy: 0.2892 - val_loss: 1.9145 - val_accuracy: 0.2756\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9087 - accuracy: 0.2751 - val_loss: 1.8170 - val_accuracy: 0.2930\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7897 - accuracy: 0.2797 - val_loss: 1.9272 - val_accuracy: 0.1994\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9337 - accuracy: 0.2068 - val_loss: 2.1173 - val_accuracy: 0.1952\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9849 - accuracy: 0.2027 - val_loss: 1.9607 - val_accuracy: 0.1894\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9268 - accuracy: 0.1781 - val_loss: 1.9322 - val_accuracy: 0.1982\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9145 - accuracy: 0.2051 - val_loss: 1.9082 - val_accuracy: 0.1980\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8496 - accuracy: 0.1963 - val_loss: 1.9274 - val_accuracy: 0.1994\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9142 - accuracy: 0.2025 - val_loss: 1.9305 - val_accuracy: 0.1974\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8868 - accuracy: 0.1910 - val_loss: 1.9319 - val_accuracy: 0.1914\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9320 - accuracy: 0.1869 - val_loss: 1.8907 - val_accuracy: 0.2008\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8683 - accuracy: 0.2121 - val_loss: 1.8267 - val_accuracy: 0.2002\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8198 - accuracy: 0.1956 - val_loss: 1.7991 - val_accuracy: 0.2024\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8172 - accuracy: 0.1963 - val_loss: 1.7970 - val_accuracy: 0.1996\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8075 - accuracy: 0.2072 - val_loss: 1.7768 - val_accuracy: 0.2080\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7831 - accuracy: 0.1901 - val_loss: 1.7731 - val_accuracy: 0.1986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7677 - accuracy: 0.2058 - val_loss: 1.7844 - val_accuracy: 0.2002\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8378 - accuracy: 0.2096 - val_loss: 1.7451 - val_accuracy: 0.2282\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6687 - accuracy: 0.2477 - val_loss: 1.7407 - val_accuracy: 0.2350\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6740 - accuracy: 0.2784 - val_loss: 1.8535 - val_accuracy: 0.2032\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8453 - accuracy: 0.2142 - val_loss: 1.8045 - val_accuracy: 0.2068\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6649 - accuracy: 0.2630 - val_loss: 1.5438 - val_accuracy: 0.3012\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5577 - accuracy: 0.2891 - val_loss: 1.5467 - val_accuracy: 0.2726\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5557 - accuracy: 0.2953 - val_loss: 1.5086 - val_accuracy: 0.2740\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5053 - accuracy: 0.2885 - val_loss: 1.5168 - val_accuracy: 0.2900\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5118 - accuracy: 0.2724 - val_loss: 1.5426 - val_accuracy: 0.2866\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6543 - accuracy: 0.2598 - val_loss: 1.7268 - val_accuracy: 0.2080\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7212 - accuracy: 0.2138 - val_loss: 1.4936 - val_accuracy: 0.2868\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4790 - accuracy: 0.2756 - val_loss: 1.6243 - val_accuracy: 0.2618\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6033 - accuracy: 0.2547 - val_loss: 1.5612 - val_accuracy: 0.2790\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5291 - accuracy: 0.2943 - val_loss: 1.4828 - val_accuracy: 0.2904\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4835 - accuracy: 0.3000 - val_loss: 1.4970 - val_accuracy: 0.2974\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5826 - accuracy: 0.2811 - val_loss: 1.6633 - val_accuracy: 0.2898\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6576 - accuracy: 0.2849 - val_loss: 1.5271 - val_accuracy: 0.2784\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5532 - accuracy: 0.2841 - val_loss: 1.6338 - val_accuracy: 0.2674\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5724 - accuracy: 0.2898 - val_loss: 1.5040 - val_accuracy: 0.2720\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6331 - accuracy: 0.2761 - val_loss: 1.5099 - val_accuracy: 0.2996\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4979 - accuracy: 0.2858 - val_loss: 1.5148 - val_accuracy: 0.2986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5051 - accuracy: 0.2857 - val_loss: 1.5681 - val_accuracy: 0.2772\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5370 - accuracy: 0.2765 - val_loss: 1.5045 - val_accuracy: 0.2692\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5084 - accuracy: 0.2819 - val_loss: 1.4823 - val_accuracy: 0.2804\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4853 - accuracy: 0.3052 - val_loss: 1.4676 - val_accuracy: 0.2994\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4547 - accuracy: 0.3040 - val_loss: 1.4766 - val_accuracy: 0.2982\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4727 - accuracy: 0.2861 - val_loss: 1.6922 - val_accuracy: 0.2646\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5828 - accuracy: 0.2896 - val_loss: 1.4872 - val_accuracy: 0.2960\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4863 - accuracy: 0.3005 - val_loss: 1.7005 - val_accuracy: 0.2214\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7107 - accuracy: 0.2240 - val_loss: 1.7183 - val_accuracy: 0.2196\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7028 - accuracy: 0.2187 - val_loss: 1.6608 - val_accuracy: 0.2410\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0579 - accuracy: 0.2760 - val_loss: 1.4638 - val_accuracy: 0.4660\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4339 - accuracy: 0.5355 - val_loss: 1.3089 - val_accuracy: 0.5384\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3329 - accuracy: 0.5208 - val_loss: 1.3038 - val_accuracy: 0.5010\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2320 - accuracy: 0.5491 - val_loss: 1.2522 - val_accuracy: 0.4832\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2616 - accuracy: 0.5339 - val_loss: 1.2395 - val_accuracy: 0.5138\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2199 - accuracy: 0.5512 - val_loss: 1.3274 - val_accuracy: 0.5088\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2919 - accuracy: 0.5294 - val_loss: 1.1982 - val_accuracy: 0.5578\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2336 - accuracy: 0.5464 - val_loss: 1.2088 - val_accuracy: 0.5080\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1785 - accuracy: 0.5737 - val_loss: 1.3174 - val_accuracy: 0.4700\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2559 - accuracy: 0.5210 - val_loss: 1.1675 - val_accuracy: 0.5600\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2201 - accuracy: 0.5484 - val_loss: 1.2743 - val_accuracy: 0.5598\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2772 - accuracy: 0.5201 - val_loss: 1.2423 - val_accuracy: 0.5660\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2393 - accuracy: 0.5427 - val_loss: 1.2265 - val_accuracy: 0.5498\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2005 - accuracy: 0.5338 - val_loss: 1.1864 - val_accuracy: 0.5282\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1350 - accuracy: 0.5590 - val_loss: 1.1839 - val_accuracy: 0.5714\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2922 - accuracy: 0.4875 - val_loss: 1.3654 - val_accuracy: 0.4062\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3351 - accuracy: 0.4614 - val_loss: 1.1990 - val_accuracy: 0.5766\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1517 - accuracy: 0.5839 - val_loss: 1.3254 - val_accuracy: 0.4692\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3097 - accuracy: 0.5179 - val_loss: 1.1948 - val_accuracy: 0.5352\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2551 - accuracy: 0.4887 - val_loss: 1.1951 - val_accuracy: 0.5034\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2117 - accuracy: 0.4948 - val_loss: 1.2338 - val_accuracy: 0.5048\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3124 - accuracy: 0.4790 - val_loss: 1.3305 - val_accuracy: 0.4194\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3211 - accuracy: 0.4221 - val_loss: 1.3540 - val_accuracy: 0.3848\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3848 - accuracy: 0.3921 - val_loss: 1.3721 - val_accuracy: 0.3728\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4382 - accuracy: 0.3504 - val_loss: 1.4225 - val_accuracy: 0.3512\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4170 - accuracy: 0.3508 - val_loss: 1.3998 - val_accuracy: 0.3752\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4194 - accuracy: 0.3675 - val_loss: 1.4466 - val_accuracy: 0.3464\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3905 - accuracy: 0.3931 - val_loss: 1.4032 - val_accuracy: 0.4028\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3807 - accuracy: 0.4040 - val_loss: 1.3051 - val_accuracy: 0.4692\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3701 - accuracy: 0.4119 - val_loss: 1.4293 - val_accuracy: 0.3646\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3782 - accuracy: 0.4137 - val_loss: 1.5116 - val_accuracy: 0.3132\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4172 - accuracy: 0.4075 - val_loss: 1.3522 - val_accuracy: 0.4444\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4017 - accuracy: 0.3892 - val_loss: 1.4691 - val_accuracy: 0.3514\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4275 - accuracy: 0.3419 - val_loss: 1.4402 - val_accuracy: 0.3352\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4232 - accuracy: 0.3655 - val_loss: 1.4384 - val_accuracy: 0.3268\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4081 - accuracy: 0.3534 - val_loss: 1.4289 - val_accuracy: 0.3642\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3986 - accuracy: 0.3656 - val_loss: 1.4413 - val_accuracy: 0.3408\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3931 - accuracy: 0.3859 - val_loss: 1.3338 - val_accuracy: 0.4194\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3504 - accuracy: 0.3998 - val_loss: 1.4091 - val_accuracy: 0.3812\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3947 - accuracy: 0.3944 - val_loss: 1.3253 - val_accuracy: 0.4354\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3085 - accuracy: 0.4577 - val_loss: 1.3217 - val_accuracy: 0.4650\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3416 - accuracy: 0.3971 - val_loss: 1.3535 - val_accuracy: 0.3914\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3272 - accuracy: 0.4154 - val_loss: 1.3147 - val_accuracy: 0.4244\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3007 - accuracy: 0.4369 - val_loss: 1.3584 - val_accuracy: 0.3668\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3354 - accuracy: 0.4314 - val_loss: 1.3252 - val_accuracy: 0.4392\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3387 - accuracy: 0.4090 - val_loss: 1.3156 - val_accuracy: 0.4580\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5273 - accuracy: 0.4098 - val_loss: 1.7529 - val_accuracy: 0.2998\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7074 - accuracy: 0.3324 - val_loss: 1.7340 - val_accuracy: 0.3362\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7151 - accuracy: 0.3553 - val_loss: 1.5714 - val_accuracy: 0.4056\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5827 - accuracy: 0.3794 - val_loss: 1.6751 - val_accuracy: 0.3178\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2308 - accuracy: 0.2099 - val_loss: 1.8056 - val_accuracy: 0.5018\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7246 - accuracy: 0.5278 - val_loss: 1.5500 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4813 - accuracy: 0.6091 - val_loss: 1.3814 - val_accuracy: 0.6186\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3248 - accuracy: 0.6449 - val_loss: 1.2629 - val_accuracy: 0.6696\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2298 - accuracy: 0.6803 - val_loss: 1.1574 - val_accuracy: 0.6552\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1599 - accuracy: 0.6564 - val_loss: 1.1751 - val_accuracy: 0.6486\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1390 - accuracy: 0.6642 - val_loss: 1.0735 - val_accuracy: 0.6698\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0193 - accuracy: 0.6969 - val_loss: 0.9912 - val_accuracy: 0.6950\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9833 - accuracy: 0.6980 - val_loss: 1.0041 - val_accuracy: 0.6830\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0022 - accuracy: 0.6931 - val_loss: 0.9740 - val_accuracy: 0.6882\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9294 - accuracy: 0.7064 - val_loss: 0.9370 - val_accuracy: 0.6934\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.9345 - accuracy: 0.7019 - val_loss: 0.9490 - val_accuracy: 0.6998\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9158 - accuracy: 0.7117 - val_loss: 0.9125 - val_accuracy: 0.7018\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9002 - accuracy: 0.7033 - val_loss: 0.9135 - val_accuracy: 0.7126\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8977 - accuracy: 0.7179 - val_loss: 0.8820 - val_accuracy: 0.6924\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9038 - accuracy: 0.6876 - val_loss: 0.8670 - val_accuracy: 0.6978\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8612 - accuracy: 0.7121 - val_loss: 0.8225 - val_accuracy: 0.7030\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8215 - accuracy: 0.7073 - val_loss: 0.8559 - val_accuracy: 0.7010\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8418 - accuracy: 0.7220 - val_loss: 0.8378 - val_accuracy: 0.7060\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8186 - accuracy: 0.7138 - val_loss: 0.8280 - val_accuracy: 0.7218\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8287 - accuracy: 0.7160 - val_loss: 0.8669 - val_accuracy: 0.6958\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8419 - accuracy: 0.7005 - val_loss: 0.7951 - val_accuracy: 0.7238\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7934 - accuracy: 0.7235 - val_loss: 0.8429 - val_accuracy: 0.7188\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8290 - accuracy: 0.7188 - val_loss: 0.8559 - val_accuracy: 0.7084\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8369 - accuracy: 0.7199 - val_loss: 0.8161 - val_accuracy: 0.7044\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7963 - accuracy: 0.7181 - val_loss: 0.7866 - val_accuracy: 0.7264\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.7671 - accuracy: 0.7259 - val_loss: 0.7735 - val_accuracy: 0.7230\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7667 - accuracy: 0.7308 - val_loss: 0.7846 - val_accuracy: 0.7176\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7577 - accuracy: 0.7257 - val_loss: 0.7911 - val_accuracy: 0.7116\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8035 - accuracy: 0.7162 - val_loss: 0.7973 - val_accuracy: 0.7120\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7915 - accuracy: 0.7188 - val_loss: 0.7940 - val_accuracy: 0.7312\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7750 - accuracy: 0.7244 - val_loss: 0.7662 - val_accuracy: 0.7192\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7748 - accuracy: 0.7254 - val_loss: 0.7841 - val_accuracy: 0.7164\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7733 - accuracy: 0.7333 - val_loss: 0.8364 - val_accuracy: 0.7006\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8318 - accuracy: 0.7176 - val_loss: 0.8563 - val_accuracy: 0.7036\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8235 - accuracy: 0.7055 - val_loss: 0.8668 - val_accuracy: 0.7006\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8581 - accuracy: 0.6956 - val_loss: 0.8597 - val_accuracy: 0.7034\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8805 - accuracy: 0.6752 - val_loss: 0.8393 - val_accuracy: 0.6940\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8122 - accuracy: 0.6978 - val_loss: 0.8102 - val_accuracy: 0.7228\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8092 - accuracy: 0.7168 - val_loss: 0.8234 - val_accuracy: 0.7060\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8393 - accuracy: 0.6992 - val_loss: 0.8306 - val_accuracy: 0.7082\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8066 - accuracy: 0.7122 - val_loss: 0.8264 - val_accuracy: 0.7214\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8300 - accuracy: 0.7029 - val_loss: 0.8381 - val_accuracy: 0.7188\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8291 - accuracy: 0.6968 - val_loss: 0.8111 - val_accuracy: 0.6994\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8271 - accuracy: 0.6888 - val_loss: 0.8473 - val_accuracy: 0.6856\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8245 - accuracy: 0.7091 - val_loss: 0.8385 - val_accuracy: 0.7142\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8279 - accuracy: 0.7179 - val_loss: 0.7916 - val_accuracy: 0.7230\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.8185 - accuracy: 0.7182 - val_loss: 0.7535 - val_accuracy: 0.7256\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7484 - accuracy: 0.7278 - val_loss: 0.7572 - val_accuracy: 0.7218\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7548 - accuracy: 0.7286 - val_loss: 0.8232 - val_accuracy: 0.6924\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3028 - accuracy: 0.0939 - val_loss: 2.2931 - val_accuracy: 0.1910\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2897 - accuracy: 0.2299 - val_loss: 2.2765 - val_accuracy: 0.3204\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2698 - accuracy: 0.3317 - val_loss: 2.2514 - val_accuracy: 0.2860\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2435 - accuracy: 0.2745 - val_loss: 2.2214 - val_accuracy: 0.2560\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2083 - accuracy: 0.2514 - val_loss: 2.1933 - val_accuracy: 0.2490\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1857 - accuracy: 0.2477 - val_loss: 2.1646 - val_accuracy: 0.2618\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1519 - accuracy: 0.2841 - val_loss: 2.1345 - val_accuracy: 0.3040\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1195 - accuracy: 0.3293 - val_loss: 2.0975 - val_accuracy: 0.3362\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0825 - accuracy: 0.3637 - val_loss: 2.0641 - val_accuracy: 0.3650\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0430 - accuracy: 0.3756 - val_loss: 2.0262 - val_accuracy: 0.3790\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0031 - accuracy: 0.3949 - val_loss: 1.9957 - val_accuracy: 0.3824\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9680 - accuracy: 0.4013 - val_loss: 1.9541 - val_accuracy: 0.3770\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9252 - accuracy: 0.4006 - val_loss: 1.9221 - val_accuracy: 0.3916\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8832 - accuracy: 0.4166 - val_loss: 1.8904 - val_accuracy: 0.4440\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8600 - accuracy: 0.4311 - val_loss: 1.8619 - val_accuracy: 0.3908\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8483 - accuracy: 0.4050 - val_loss: 1.8473 - val_accuracy: 0.3748\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8232 - accuracy: 0.3974 - val_loss: 1.8082 - val_accuracy: 0.3836\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7827 - accuracy: 0.4042 - val_loss: 1.8192 - val_accuracy: 0.4022\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7821 - accuracy: 0.4108 - val_loss: 1.7776 - val_accuracy: 0.3912\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7422 - accuracy: 0.4167 - val_loss: 1.7520 - val_accuracy: 0.3920\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7398 - accuracy: 0.3982 - val_loss: 1.7493 - val_accuracy: 0.3858\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6944 - accuracy: 0.4175 - val_loss: 1.7246 - val_accuracy: 0.3854\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6964 - accuracy: 0.3983 - val_loss: 1.7089 - val_accuracy: 0.3860\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6819 - accuracy: 0.4045 - val_loss: 1.6906 - val_accuracy: 0.3796\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6679 - accuracy: 0.4012 - val_loss: 1.6697 - val_accuracy: 0.3926\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6376 - accuracy: 0.4120 - val_loss: 1.6586 - val_accuracy: 0.3932\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6450 - accuracy: 0.4099 - val_loss: 1.6840 - val_accuracy: 0.3816\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6418 - accuracy: 0.4133 - val_loss: 1.6332 - val_accuracy: 0.3924\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.6210 - accuracy: 0.4058 - val_loss: 1.6167 - val_accuracy: 0.3972\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5968 - accuracy: 0.4212 - val_loss: 1.6276 - val_accuracy: 0.3976\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5943 - accuracy: 0.4263 - val_loss: 1.6039 - val_accuracy: 0.4086\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5880 - accuracy: 0.4190 - val_loss: 1.5914 - val_accuracy: 0.3914\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5759 - accuracy: 0.4202 - val_loss: 1.5830 - val_accuracy: 0.3962\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5560 - accuracy: 0.4209 - val_loss: 1.5586 - val_accuracy: 0.4042\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5337 - accuracy: 0.4180 - val_loss: 1.5434 - val_accuracy: 0.4280\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5416 - accuracy: 0.4335 - val_loss: 1.5418 - val_accuracy: 0.4218\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5257 - accuracy: 0.4367 - val_loss: 1.5605 - val_accuracy: 0.4088\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5341 - accuracy: 0.4155 - val_loss: 1.5324 - val_accuracy: 0.4124\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5189 - accuracy: 0.4607 - val_loss: 1.5175 - val_accuracy: 0.4394\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5052 - accuracy: 0.4589 - val_loss: 1.5421 - val_accuracy: 0.4236\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4865 - accuracy: 0.4453 - val_loss: 1.5053 - val_accuracy: 0.4082\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4906 - accuracy: 0.4465 - val_loss: 1.4910 - val_accuracy: 0.4300\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4584 - accuracy: 0.4564 - val_loss: 1.4782 - val_accuracy: 0.4208\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4476 - accuracy: 0.4566 - val_loss: 1.4670 - val_accuracy: 0.4412\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4665 - accuracy: 0.4532 - val_loss: 1.4846 - val_accuracy: 0.4630\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4691 - accuracy: 0.4710 - val_loss: 1.4698 - val_accuracy: 0.4588\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4395 - accuracy: 0.4609 - val_loss: 1.4512 - val_accuracy: 0.4396\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4264 - accuracy: 0.4518 - val_loss: 1.4654 - val_accuracy: 0.4088\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4396 - accuracy: 0.4497 - val_loss: 1.4388 - val_accuracy: 0.4342\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4199 - accuracy: 0.4571 - val_loss: 1.4242 - val_accuracy: 0.4552\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.9947 - accuracy: 0.2889 - val_loss: 1.4088 - val_accuracy: 0.5382\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3745 - accuracy: 0.5246 - val_loss: 1.3043 - val_accuracy: 0.5172\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2553 - accuracy: 0.5519 - val_loss: 1.1157 - val_accuracy: 0.5988\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1655 - accuracy: 0.5993 - val_loss: 1.0520 - val_accuracy: 0.6426\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0902 - accuracy: 0.6248 - val_loss: 1.0555 - val_accuracy: 0.6474\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0312 - accuracy: 0.6278 - val_loss: 1.0962 - val_accuracy: 0.5854\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1096 - accuracy: 0.5748 - val_loss: 1.0313 - val_accuracy: 0.6124\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0362 - accuracy: 0.6034 - val_loss: 1.1510 - val_accuracy: 0.5934\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1430 - accuracy: 0.5755 - val_loss: 1.0529 - val_accuracy: 0.6162\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0707 - accuracy: 0.6010 - val_loss: 1.0238 - val_accuracy: 0.6318\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0509 - accuracy: 0.6210 - val_loss: 1.0945 - val_accuracy: 0.5988\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1327 - accuracy: 0.5809 - val_loss: 1.2744 - val_accuracy: 0.5380\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2504 - accuracy: 0.5441 - val_loss: 1.0933 - val_accuracy: 0.6134\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0831 - accuracy: 0.6007 - val_loss: 1.0253 - val_accuracy: 0.6252\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0858 - accuracy: 0.5810 - val_loss: 1.1256 - val_accuracy: 0.5734\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1346 - accuracy: 0.5599 - val_loss: 1.1252 - val_accuracy: 0.5560\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1250 - accuracy: 0.5644 - val_loss: 1.2180 - val_accuracy: 0.5278\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.1721 - accuracy: 0.5439 - val_loss: 1.0740 - val_accuracy: 0.6318\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0879 - accuracy: 0.6072 - val_loss: 1.1217 - val_accuracy: 0.5192\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0746 - accuracy: 0.5726 - val_loss: 1.2448 - val_accuracy: 0.4904\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2574 - accuracy: 0.4686 - val_loss: 1.3666 - val_accuracy: 0.4432\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2939 - accuracy: 0.4556 - val_loss: 1.2092 - val_accuracy: 0.4952\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2534 - accuracy: 0.5186 - val_loss: 1.2926 - val_accuracy: 0.4734\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3035 - accuracy: 0.4740 - val_loss: 1.3296 - val_accuracy: 0.4382\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2667 - accuracy: 0.4691 - val_loss: 1.2673 - val_accuracy: 0.5442\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2751 - accuracy: 0.4998 - val_loss: 1.3717 - val_accuracy: 0.4308\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3037 - accuracy: 0.4374 - val_loss: 1.2180 - val_accuracy: 0.4916\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2609 - accuracy: 0.4835 - val_loss: 1.2766 - val_accuracy: 0.4674\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2772 - accuracy: 0.4927 - val_loss: 1.2168 - val_accuracy: 0.5276\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2286 - accuracy: 0.5043 - val_loss: 1.2588 - val_accuracy: 0.4360\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2415 - accuracy: 0.4786 - val_loss: 1.4783 - val_accuracy: 0.4644\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4010 - accuracy: 0.4490 - val_loss: 1.3624 - val_accuracy: 0.4568\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3596 - accuracy: 0.4401 - val_loss: 1.3550 - val_accuracy: 0.4316\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2895 - accuracy: 0.4805 - val_loss: 1.3457 - val_accuracy: 0.4788\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2612 - accuracy: 0.5149 - val_loss: 1.2964 - val_accuracy: 0.4814\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2455 - accuracy: 0.4897 - val_loss: 1.2593 - val_accuracy: 0.4780\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2880 - accuracy: 0.4829 - val_loss: 1.4896 - val_accuracy: 0.4074\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4349 - accuracy: 0.3954 - val_loss: 1.3642 - val_accuracy: 0.4624\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3651 - accuracy: 0.4439 - val_loss: 1.4459 - val_accuracy: 0.4138\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4494 - accuracy: 0.4519 - val_loss: 1.3458 - val_accuracy: 0.4706\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3392 - accuracy: 0.4836 - val_loss: 1.4467 - val_accuracy: 0.4414\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4110 - accuracy: 0.4410 - val_loss: 1.3798 - val_accuracy: 0.4674\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3341 - accuracy: 0.4554 - val_loss: 1.3008 - val_accuracy: 0.4484\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2802 - accuracy: 0.4551 - val_loss: 1.3164 - val_accuracy: 0.4592\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3190 - accuracy: 0.4503 - val_loss: 1.5418 - val_accuracy: 0.3688\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4300 - accuracy: 0.4072 - val_loss: 1.5648 - val_accuracy: 0.3812\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5017 - accuracy: 0.3773 - val_loss: 1.7140 - val_accuracy: 0.3318\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5925 - accuracy: 0.3735 - val_loss: 1.5204 - val_accuracy: 0.4160\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5605 - accuracy: 0.3778 - val_loss: 1.3296 - val_accuracy: 0.4170\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.3332 - accuracy: 0.4548 - val_loss: 1.2133 - val_accuracy: 0.5242\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2300 - accuracy: 0.2659 - val_loss: 2.0879 - val_accuracy: 0.3000\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4831 - accuracy: 0.4338 - val_loss: 1.9457 - val_accuracy: 0.2708\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4019 - accuracy: 0.4222 - val_loss: 1.8583 - val_accuracy: 0.2662\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4996 - accuracy: 0.3942 - val_loss: 1.6006 - val_accuracy: 0.3374\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5000 - accuracy: 0.3876 - val_loss: 1.6880 - val_accuracy: 0.3766\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5837 - accuracy: 0.3356 - val_loss: 2.1384 - val_accuracy: 0.2082\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6679 - accuracy: 0.2961 - val_loss: 1.7111 - val_accuracy: 0.2576\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7638 - accuracy: 0.2685 - val_loss: 1.9586 - val_accuracy: 0.3044\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6516 - accuracy: 0.2964 - val_loss: 1.7316 - val_accuracy: 0.2702\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6348 - accuracy: 0.2861 - val_loss: 1.5673 - val_accuracy: 0.2830\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5294 - accuracy: 0.3115 - val_loss: 1.5153 - val_accuracy: 0.3616\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5651 - accuracy: 0.3140 - val_loss: 1.7071 - val_accuracy: 0.2884\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7397 - accuracy: 0.2907 - val_loss: 1.9066 - val_accuracy: 0.2252\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7029 - accuracy: 0.2734 - val_loss: 1.8456 - val_accuracy: 0.1868\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7493 - accuracy: 0.2625 - val_loss: 1.6689 - val_accuracy: 0.2816\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5177 - accuracy: 0.3255 - val_loss: 1.6447 - val_accuracy: 0.3278\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5623 - accuracy: 0.3141 - val_loss: 1.8316 - val_accuracy: 0.2528\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5449 - accuracy: 0.3066 - val_loss: 1.6345 - val_accuracy: 0.3026\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5204 - accuracy: 0.3194 - val_loss: 1.5304 - val_accuracy: 0.3022\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4899 - accuracy: 0.3121 - val_loss: 1.4946 - val_accuracy: 0.3272\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4807 - accuracy: 0.3141 - val_loss: 1.5189 - val_accuracy: 0.3106\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4725 - accuracy: 0.3214 - val_loss: 1.6571 - val_accuracy: 0.2858\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.5665 - accuracy: 0.3166 - val_loss: 1.5683 - val_accuracy: 0.2866\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4727 - accuracy: 0.3087 - val_loss: 1.5536 - val_accuracy: 0.3348\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4731 - accuracy: 0.3317 - val_loss: 1.5415 - val_accuracy: 0.3324\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4630 - accuracy: 0.3310 - val_loss: 1.5569 - val_accuracy: 0.3068\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4768 - accuracy: 0.2994 - val_loss: 1.5352 - val_accuracy: 0.2618\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4613 - accuracy: 0.3135 - val_loss: 1.5773 - val_accuracy: 0.2858\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4381 - accuracy: 0.3694 - val_loss: 1.4289 - val_accuracy: 0.3310\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4132 - accuracy: 0.3658 - val_loss: 1.6274 - val_accuracy: 0.2922\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4023 - accuracy: 0.3725 - val_loss: 1.4246 - val_accuracy: 0.3596\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4163 - accuracy: 0.3497 - val_loss: 1.5181 - val_accuracy: 0.2850\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4789 - accuracy: 0.3208 - val_loss: 1.6986 - val_accuracy: 0.2364\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6889 - accuracy: 0.2547 - val_loss: 1.6344 - val_accuracy: 0.2842\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6697 - accuracy: 0.2646 - val_loss: 1.6217 - val_accuracy: 0.2466\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6514 - accuracy: 0.2753 - val_loss: 1.6655 - val_accuracy: 0.2976\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6346 - accuracy: 0.2937 - val_loss: 1.6149 - val_accuracy: 0.2768\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6579 - accuracy: 0.2772 - val_loss: 1.7565 - val_accuracy: 0.2994\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6604 - accuracy: 0.2738 - val_loss: 1.7117 - val_accuracy: 0.2148\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6966 - accuracy: 0.2277 - val_loss: 1.7763 - val_accuracy: 0.2126\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6742 - accuracy: 0.2616 - val_loss: 1.4846 - val_accuracy: 0.3426\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4798 - accuracy: 0.3438 - val_loss: 1.7046 - val_accuracy: 0.2906\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4471 - accuracy: 0.3668 - val_loss: 1.4491 - val_accuracy: 0.3504\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.4380 - accuracy: 0.3540 - val_loss: 1.9829 - val_accuracy: 0.2092\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7196 - accuracy: 0.2346 - val_loss: 1.7156 - val_accuracy: 0.2246\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7045 - accuracy: 0.2290 - val_loss: 1.7023 - val_accuracy: 0.2324\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6867 - accuracy: 0.2351 - val_loss: 2.1513 - val_accuracy: 0.2374\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.6921 - accuracy: 0.2393 - val_loss: 1.7926 - val_accuracy: 0.2176\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.6995 - accuracy: 0.2252 - val_loss: 1.8650 - val_accuracy: 0.1986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.7066 - accuracy: 0.2383 - val_loss: 1.8853 - val_accuracy: 0.1974\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.3026 - accuracy: 0.1033 - val_loss: 2.3027 - val_accuracy: 0.0960\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3022 - accuracy: 0.0953 - val_loss: 2.3028 - val_accuracy: 0.0960\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3017 - accuracy: 0.0991 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3015 - accuracy: 0.1145 - val_loss: 2.3031 - val_accuracy: 0.0960\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3009 - accuracy: 0.1051 - val_loss: 2.3033 - val_accuracy: 0.0960\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.1158 - val_loss: 2.3034 - val_accuracy: 0.0960\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3028 - accuracy: 0.1073 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3016 - accuracy: 0.1050 - val_loss: 2.3037 - val_accuracy: 0.0960\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1097 - val_loss: 2.3038 - val_accuracy: 0.0960\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3015 - accuracy: 0.1046 - val_loss: 2.3040 - val_accuracy: 0.0960\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3007 - accuracy: 0.1050 - val_loss: 2.3041 - val_accuracy: 0.0960\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3017 - accuracy: 0.1024 - val_loss: 2.3042 - val_accuracy: 0.0960\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3015 - accuracy: 0.1030 - val_loss: 2.3043 - val_accuracy: 0.0960\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3014 - accuracy: 0.1074 - val_loss: 2.3044 - val_accuracy: 0.0960\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3011 - accuracy: 0.1021 - val_loss: 2.3045 - val_accuracy: 0.0960\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.2999 - accuracy: 0.1081 - val_loss: 2.3045 - val_accuracy: 0.0960\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3010 - accuracy: 0.1122 - val_loss: 2.3046 - val_accuracy: 0.0960\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2991 - accuracy: 0.1085 - val_loss: 2.3046 - val_accuracy: 0.0960\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2988 - accuracy: 0.1142 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2996 - accuracy: 0.1095 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3013 - accuracy: 0.1037 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2991 - accuracy: 0.1154 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3013 - accuracy: 0.0975 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3002 - accuracy: 0.1069 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2990 - accuracy: 0.1096 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2995 - accuracy: 0.1051 - val_loss: 2.3047 - val_accuracy: 0.0960\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.1041 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3005 - accuracy: 0.1077 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3002 - accuracy: 0.1084 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.1093 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1095 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.1117 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3013 - accuracy: 0.1108 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.1036 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3003 - accuracy: 0.1072 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3012 - accuracy: 0.1069 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3000 - accuracy: 0.1039 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3009 - accuracy: 0.1085 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3007 - accuracy: 0.1022 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2996 - accuracy: 0.1128 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3008 - accuracy: 0.1094 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3025 - accuracy: 0.1048 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3007 - accuracy: 0.1095 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3002 - accuracy: 0.1055 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3006 - accuracy: 0.1097 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.1040 - val_loss: 2.3049 - val_accuracy: 0.0960\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3003 - accuracy: 0.1038 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 2.3008 - accuracy: 0.1043 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3010 - accuracy: 0.1063 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.3014 - accuracy: 0.1026 - val_loss: 2.3048 - val_accuracy: 0.0960\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.0933 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1037 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0945 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1020 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0988 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0953 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0929 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1055 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1031 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1033 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0956 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1036 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0921 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0934 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0933 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1037 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1037 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1035 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1012 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0947 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0911 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0905 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0960 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0916 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0939 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1024 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1111 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0933 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1038 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1007 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1061 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0947 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1042 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1030 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0952 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1001 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0938 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0922 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1015 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0954 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0968 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0962 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0932 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1033 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0974 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1004 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0905 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1070 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1009 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0940 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0962 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0986 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0944 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0990 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1011 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1043 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1028 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0885 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1013 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0919 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0957 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1018 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.1006 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1010 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0966 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0960 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0996 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0922 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0949 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0971 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0984 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0940 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0923 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1017 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0981 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0921 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0937 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0965 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0941 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1044 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1005 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0983 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1032 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1046 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0955 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0939 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1014 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0921 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0962 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0959 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0956 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0938 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0912 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0979 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0963 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0973 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0972 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0951 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0958 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0948 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0998 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.1035 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.0964 - val_loss: nan - val_accuracy: 0.0986\n"
     ]
    }
   ],
   "source": [
    "# fit the models\r\n",
    "info = []\r\n",
    "for m in model:\r\n",
    "    i = m.fit(X_train, to_categorical(Y_train), validation_data=(X_test, to_categorical(Y_test)), epochs=50, verbose = 1)\r\n",
    "    info.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtV91C-yUJai",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612621199E12,
     "user_tz": -210.0,
     "elapsed": 23875.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "7f515428-642e-478f-aa19-8c73fe6e6628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations:  relu-relu\n",
      "Train Accuracy:  10.74\n",
      "Test Accuracy:  9.64\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 479   0   0   0   0   1   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   2   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 497   0   0   0   0   3   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  relu-sigmoid\n",
      "Train Accuracy:  86.14\n",
      "Test Accuracy:  83.62\n",
      "Predicted Values:  [2 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[422   3  11  11   2   0  33   0  11   0]\n",
      " [  2 451  10   9   2   0   1   0   1   0]\n",
      " [  8   0 426   4  34   0  38   0  13   0]\n",
      " [ 33   4  10 398  12   0  20   0   3   0]\n",
      " [  0   0 117   8 317   0  56   0   2   0]\n",
      " [  1   0   0   0   0 447   1  22  10  14]\n",
      " [ 96   2  61   1  25   0 292   0  16   0]\n",
      " [  0   0   0   0   0  14   0 488   5  15]\n",
      " [  1   0   6   1   1   1   4   2 484   0]\n",
      " [  0   0   0   0   0  18   0  42   2 456]]\n",
      "---------------------------------\n",
      "Activations:  relu-softmax\n",
      "Train Accuracy:  30.08\n",
      "Test Accuracy:  28.68\n",
      "Predicted Values:  [3 8 8 ... 7 7 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 417   0   0   0   1  75   0]\n",
      " [  0   0   0 465   0   0   0   0  11   0]\n",
      " [  0   0   0   8   0   0   0   0 515   0]\n",
      " [  0   0   1 443   0   0   0   0  36   0]\n",
      " [  0   0   0  62   0   0   0   0 438   0]\n",
      " [  0   0   0   1   0   0   0 487   7   0]\n",
      " [  0   0   0 115   0   0   0   0 378   0]\n",
      " [  0   0   0   0   0   0   0 520   2   0]\n",
      " [  0   0   0  11   0   0   0  18 471   0]\n",
      " [  0   0   0   0   0   0   0 517   1   0]]\n",
      "---------------------------------\n",
      "Activations:  relu-tanh\n",
      "Train Accuracy:  70.9\n",
      "Test Accuracy:  70.84\n",
      "Predicted Values:  [1 8 2 ... 5 8 0]\n",
      "Confusion Matrix:\n",
      " [[322   3  10 103  13   0  22   0  20   0]\n",
      " [  3 436   7  25   5   0   0   0   0   0]\n",
      " [  2   0 280   9 205   0   5   0  22   0]\n",
      " [ 31   6   1 405  21   0  10   1   4   1]\n",
      " [  0   0 143  46 308   0   1   0   2   0]\n",
      " [  1   0   0   0   0 368   0  36   7  83]\n",
      " [ 52   0  85  68 224   0  34   0  30   0]\n",
      " [  0   0   0   0   0  32   0 414   1  75]\n",
      " [  2   0   3   0  12   6   1   2 472   2]\n",
      " [  0   0   0   0   0   1   0  13   1 503]]\n",
      "---------------------------------\n",
      "Activations:  relu-exponential\n",
      "Train Accuracy:  9.82\n",
      "Test Accuracy:  9.86\n",
      "Predicted Values:  [0 0 0 ... 0 0 0]\n",
      "Confusion Matrix:\n",
      " [[493   0   0   0   0   0   0   0   0   0]\n",
      " [476   0   0   0   0   0   0   0   0   0]\n",
      " [523   0   0   0   0   0   0   0   0   0]\n",
      " [480   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [495   0   0   0   0   0   0   0   0   0]\n",
      " [493   0   0   0   0   0   0   0   0   0]\n",
      " [522   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [518   0   0   0   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  sigmoid-relu\n",
      "Train Accuracy:  68.76\n",
      "Test Accuracy:  67.76\n",
      "Predicted Values:  [4 8 2 ... 5 5 6]\n",
      "Confusion Matrix:\n",
      " [[219   1  15  19  26   0 207   0   6   0]\n",
      " [  8 427   9  23   4   0   4   0   0   1]\n",
      " [  6   0 335   1 116   0  60   0   5   0]\n",
      " [ 53   3   2 298 112   0  11   0   1   0]\n",
      " [  0   0 160   7 313   0  19   0   1   0]\n",
      " [  0   0   0   0   2 317   0  94  24  58]\n",
      " [ 45   0 132   8 170   0 135   0   3   0]\n",
      " [  0   0   0   0   0   4   0 438   8  72]\n",
      " [  8   0   2  26   5   2  37   5 414   1]\n",
      " [  0   0   0   0   0   3   0  22   1 492]]\n",
      "---------------------------------\n",
      "Activations:  sigmoid-sigmoid\n",
      "Train Accuracy:  79.1\n",
      "Test Accuracy:  77.26\n",
      "Predicted Values:  [1 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[399   5   3  54   6   0  15   0  11   0]\n",
      " [  1 446  10  18   1   0   0   0   0   0]\n",
      " [ 14   1 220   8 203   0  60   0  17   0]\n",
      " [ 24   3   1 424  13   0  13   0   2   0]\n",
      " [  0   2  24  40 406   0  23   0   5   0]\n",
      " [  0   0   0   1   0 397   0  46  11  40]\n",
      " [113   1  33  27 144   0 157   0  18   0]\n",
      " [  0   0   0   0   0  10   0 454   2  56]\n",
      " [  2   0   2   5   4   2   6   2 477   0]\n",
      " [  0   0   0   0   0   7   0  27   1 483]]\n",
      "---------------------------------\n",
      "Activations:  sigmoid-softmax\n",
      "Train Accuracy:  43.94\n",
      "Test Accuracy:  42.84\n",
      "Predicted Values:  [3 8 2 ... 8 8 2]\n",
      "Confusion Matrix:\n",
      " [[ 77  13 291  54   0   0  45   0  13   0]\n",
      " [  1 459  11   5   0   0   0   0   0   0]\n",
      " [  8   1 492   7   0   0   5   0  10   0]\n",
      " [ 17 360  23  74   0   0   4   0   2   0]\n",
      " [ 32   7 410  41   0   0   8   0   2   0]\n",
      " [  0   1   0   1   0  31   0 384  78   0]\n",
      " [ 27   4 402  27   0   0  17   0  16   0]\n",
      " [  0   0   0   0   0   0   0 517   5   0]\n",
      " [  0   1  18   2   0   1   0   3 475   0]\n",
      " [  0   0   0   0   0   3   1 513   1   0]]\n",
      "---------------------------------\n",
      "Activations:  sigmoid-tanh\n",
      "Train Accuracy:  71.36\n",
      "Test Accuracy:  71.92\n",
      "Predicted Values:  [1 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[405   5  26  34   7   0   9   0   7   0]\n",
      " [  3 432  11  28   2   0   0   0   0   0]\n",
      " [  3   2 370   4  92   1  31   0  20   0]\n",
      " [ 33  51  22 350  18   0   6   0   0   0]\n",
      " [  4   6 132  38 284   0  31   0   5   0]\n",
      " [  1   0   0   1   0 411   0  33  10  39]\n",
      " [120   5  96   8 188   0  55   0  21   0]\n",
      " [  0   0   0   0   0  54   0 428   3  37]\n",
      " [  2   1  16   1   2   3   3   2 470   0]\n",
      " [  0   0   0   0   0 110   0  16   1 391]]\n",
      "---------------------------------\n",
      "Activations:  sigmoid-exponential\n",
      "Train Accuracy:  45.56\n",
      "Test Accuracy:  46.34\n",
      "Predicted Values:  [6 8 6 ... 5 9 6]\n",
      "Confusion Matrix:\n",
      " [[  1   1   3   1   0   0 458   1  28   0]\n",
      " [  0 392   3   0   0   0  79   0   2   0]\n",
      " [  0   0 121   0   1   0 374   0  26   1]\n",
      " [  0   7   0   0   0   0 446   2  24   1]\n",
      " [  0   0 155   0   0   0 334   0  11   0]\n",
      " [  0   0   0   0   1 315   1  79   3  96]\n",
      " [  1   0  65   0   0   0 394   0  33   0]\n",
      " [  0   0   0   0   0 153   0 363   0   6]\n",
      " [  0   0   2   0   1  16  11  54 412   4]\n",
      " [  0   0   0   0   0   4   0 193   2 319]]\n",
      "---------------------------------\n",
      "Activations:  softmax-relu\n",
      "Train Accuracy:  30.38\n",
      "Test Accuracy:  30.06\n",
      "Predicted Values:  [1 2 2 ... 7 7 2]\n",
      "Confusion Matrix:\n",
      " [[  0  94 399   0   0   0   0   0   0   0]\n",
      " [  0 460  16   0   0   0   0   0   0   0]\n",
      " [  0   2 521   0   0   0   0   0   0   0]\n",
      " [  1 411  68   0   0   0   0   0   0   0]\n",
      " [  0  29 471   0   0   0   0   0   0   0]\n",
      " [  0   4  12   0   0   0   0 479   0   0]\n",
      " [  0  35 458   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 522   0   0]\n",
      " [  0  58 409   0   0   0   0  33   0   0]\n",
      " [  0   4   7   0   0   0   0 507   0   0]]\n",
      "---------------------------------\n",
      "Activations:  softmax-sigmoid\n",
      "Train Accuracy:  37.22\n",
      "Test Accuracy:  36.1\n",
      "Predicted Values:  [6 6 6 ... 7 7 6]\n",
      "Confusion Matrix:\n",
      " [[  0   9   0   0   0   0 481   0   3   0]\n",
      " [  0 426   0   0   0   0  50   0   0   0]\n",
      " [  0   1   0   0   0   0 521   0   1   0]\n",
      " [  0 291   0   0   0   0 189   0   0   0]\n",
      " [  0   2   0   0   0   0 498   0   0   0]\n",
      " [  0   0   0   0   0   0   2 487   6   0]\n",
      " [  0   2   0   0   0   0 489   0   2   0]\n",
      " [  0   0   0   0   0   0   0 520   2   0]\n",
      " [  0   1   0   0   0   0 111  18 370   0]\n",
      " [  0   0   0   0   0   0   1 516   1   0]]\n",
      "---------------------------------\n",
      "Activations:  softmax-softmax\n",
      "Train Accuracy:  10.72\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  softmax-tanh\n",
      "Train Accuracy:  21.1\n",
      "Test Accuracy:  20.08\n",
      "Predicted Values:  [3 3 3 ... 7 7 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 489   0   0   0   4   0   0]\n",
      " [  0   0   0 475   0   0   0   1   0   0]\n",
      " [  0   0   0 513   0   0   0   5   5   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 498   0   0   0   0   2   0]\n",
      " [  0   0   0   2   0   0   0 493   0   0]\n",
      " [  0   0   0 484   0   0   0   8   1   0]\n",
      " [  0   0   0   0   0   0   0 522   0   0]\n",
      " [  0   0   0 152   0   0   0 346   2   0]\n",
      " [  0   0   0   0   0   0   0 518   0   0]]\n",
      "---------------------------------\n",
      "Activations:  softmax-exponential\n",
      "Train Accuracy:  23.46\n",
      "Test Accuracy:  24.1\n",
      "Predicted Values:  [1 1 2 ... 5 5 1]\n",
      "Confusion Matrix:\n",
      " [[  0 486   7   0   0   0   0   0   0   0]\n",
      " [  0 472   4   0   0   0   0   0   0   0]\n",
      " [  0 342 179   0   0   1   0   0   1   0]\n",
      " [  0 479   1   0   0   0   0   0   0   0]\n",
      " [  0 328 172   0   0   0   0   0   0   0]\n",
      " [  0   5   4   0   0 486   0   0   0   0]\n",
      " [  0 425  67   0   0   0   0   0   1   0]\n",
      " [  0   0   1   0   0 521   0   0   0   0]\n",
      " [  0 129 150   0   0 153   0   0  68   0]\n",
      " [  0   4   0   0   0 514   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  tanh-relu\n",
      "Train Accuracy:  32.6\n",
      "Test Accuracy:  31.78\n",
      "Predicted Values:  [0 3 3 ... 7 7 3]\n",
      "Confusion Matrix:\n",
      " [[  0  16   0 465   3   0   4   4   0   1]\n",
      " [  0 420   1  54   0   0   0   0   0   1]\n",
      " [  0   2   3 468  14   2   1  13   0  20]\n",
      " [  1  18   0 459   1   0   1   0   0   0]\n",
      " [  0   2   2 464  15   1   0   2   0  14]\n",
      " [  0   0   1  34   0 172   3 274   2   9]\n",
      " [  0   2   1 451   4   0   1   7   0  27]\n",
      " [  0   0   0   1   0   2   0 519   0   0]\n",
      " [  2   0   0 282   0   1   2 202   0  11]\n",
      " [  0   0   0 162   0   3   0 353   0   0]]\n",
      "---------------------------------\n",
      "Activations:  tanh-sigmoid\n",
      "Train Accuracy:  69.92\n",
      "Test Accuracy:  69.24\n",
      "Predicted Values:  [3 8 2 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[416   4   4  41   1   0  17   0  10   0]\n",
      " [  6 418   4  42   0   0   5   0   1   0]\n",
      " [ 33   0 284   9  18   0 156   0  23   0]\n",
      " [ 62   2   0 407   0   0   8   0   1   0]\n",
      " [ 30   7 200  59  47   0 152   0   5   0]\n",
      " [  1   0   0   1   0 304   1  97   8  83]\n",
      " [156   2 115  22   4   0 176   0  18   0]\n",
      " [  0   0   0   0   0   6   0 461   1  54]\n",
      " [  3   1   1   1   0   0   8   5 480   1]\n",
      " [  0   0   0   1   0   1   0  46   1 469]]\n",
      "---------------------------------\n",
      "Activations:  tanh-softmax\n",
      "Train Accuracy:  46.96\n",
      "Test Accuracy:  45.52\n",
      "Predicted Values:  [1 2 2 ... 7 7 3]\n",
      "Confusion Matrix:\n",
      " [[  1   3  31 450   0   0   8   0   0   0]\n",
      " [  0 439  10  27   0   0   0   0   0   0]\n",
      " [  2   0 490  20   0   0   8   0   3   0]\n",
      " [  4   7  10 455   0   0   4   0   0   0]\n",
      " [  0   1 396  85   0   0  18   0   0   0]\n",
      " [  0   1   2   1   0   0   1 453  10  27]\n",
      " [  0   1 313 160   0   0  18   0   1   0]\n",
      " [  0   0   0   0   0   0   0 512   0  10]\n",
      " [ 18   0 348  24   0   0   8  15  72  15]\n",
      " [  0   0   2   0   0   0   2 194  31 289]]\n",
      "---------------------------------\n",
      "Activations:  tanh-tanh\n",
      "Train Accuracy:  51.14\n",
      "Test Accuracy:  52.42\n",
      "Predicted Values:  [0 8 4 ... 5 5 0]\n",
      "Confusion Matrix:\n",
      " [[440   2   2   1  40   1   0   0   4   3]\n",
      " [103 364   0   3   6   0   0   0   0   0]\n",
      " [ 29   0   6   1 478   0   0   0   5   4]\n",
      " [420  19   0  19  20   0   0   0   0   2]\n",
      " [101   0   3   0 395   0   0   0   0   1]\n",
      " [  1   0   0   0   1 291   0  62  21 119]\n",
      " [135   0   2   2 346   1   0   0   3   4]\n",
      " [  0   0   0   0   0  58   0 346   2 116]\n",
      " [  9   0   3   2  47  26   0   1 357  55]\n",
      " [  0   0   1   0   9  50   0   2  53 403]]\n",
      "---------------------------------\n",
      "Activations:  tanh-exponential\n",
      "Train Accuracy:  19.08\n",
      "Test Accuracy:  19.74\n",
      "Predicted Values:  [8 5 1 ... 5 5 1]\n",
      "Confusion Matrix:\n",
      " [[  4 485   2   0   0   2   0   0   0   0]\n",
      " [  0 475   0   0   0   0   1   0   0   0]\n",
      " [  0 509  12   0   0   2   0   0   0   0]\n",
      " [  0 472   0   2   0   1   0   0   5   0]\n",
      " [  0 498   1   0   0   1   0   0   0   0]\n",
      " [  0   4   0   0   0 489   1   1   0   0]\n",
      " [  0 487   3   0   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0 522   0   0   0   0]\n",
      " [  0  80   0   0   0 415   0   0   5   0]\n",
      " [  0  22   0   0   0 496   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  exponential-relu\n",
      "Train Accuracy:  10.72\n",
      "Test Accuracy:  9.6\n",
      "Predicted Values:  [3 3 3 ... 3 3 3]\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 476   0   0   0   0   0   0]\n",
      " [  0   0   0 523   0   0   0   0   0   0]\n",
      " [  0   0   0 480   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 495   0   0   0   0   0   0]\n",
      " [  0   0   0 493   0   0   0   0   0   0]\n",
      " [  0   0   0 522   0   0   0   0   0   0]\n",
      " [  0   0   0 500   0   0   0   0   0   0]\n",
      " [  0   0   0 518   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  exponential-sigmoid\n",
      "Train Accuracy:  9.82\n",
      "Test Accuracy:  9.86\n",
      "Predicted Values:  [0 0 0 ... 0 0 0]\n",
      "Confusion Matrix:\n",
      " [[493   0   0   0   0   0   0   0   0   0]\n",
      " [476   0   0   0   0   0   0   0   0   0]\n",
      " [523   0   0   0   0   0   0   0   0   0]\n",
      " [480   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [495   0   0   0   0   0   0   0   0   0]\n",
      " [493   0   0   0   0   0   0   0   0   0]\n",
      " [522   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [518   0   0   0   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  exponential-softmax\n",
      "Train Accuracy:  9.82\n",
      "Test Accuracy:  9.86\n",
      "Predicted Values:  [0 0 0 ... 0 0 0]\n",
      "Confusion Matrix:\n",
      " [[493   0   0   0   0   0   0   0   0   0]\n",
      " [476   0   0   0   0   0   0   0   0   0]\n",
      " [523   0   0   0   0   0   0   0   0   0]\n",
      " [480   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [495   0   0   0   0   0   0   0   0   0]\n",
      " [493   0   0   0   0   0   0   0   0   0]\n",
      " [522   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [518   0   0   0   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  exponential-tanh\n",
      "Train Accuracy:  9.82\n",
      "Test Accuracy:  9.86\n",
      "Predicted Values:  [0 0 0 ... 0 0 0]\n",
      "Confusion Matrix:\n",
      " [[493   0   0   0   0   0   0   0   0   0]\n",
      " [476   0   0   0   0   0   0   0   0   0]\n",
      " [523   0   0   0   0   0   0   0   0   0]\n",
      " [480   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [495   0   0   0   0   0   0   0   0   0]\n",
      " [493   0   0   0   0   0   0   0   0   0]\n",
      " [522   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [518   0   0   0   0   0   0   0   0   0]]\n",
      "---------------------------------\n",
      "Activations:  exponential-exponential\n",
      "Train Accuracy:  9.82\n",
      "Test Accuracy:  9.86\n",
      "Predicted Values:  [0 0 0 ... 0 0 0]\n",
      "Confusion Matrix:\n",
      " [[493   0   0   0   0   0   0   0   0   0]\n",
      " [476   0   0   0   0   0   0   0   0   0]\n",
      " [523   0   0   0   0   0   0   0   0   0]\n",
      " [480   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [495   0   0   0   0   0   0   0   0   0]\n",
      " [493   0   0   0   0   0   0   0   0   0]\n",
      " [522   0   0   0   0   0   0   0   0   0]\n",
      " [500   0   0   0   0   0   0   0   0   0]\n",
      " [518   0   0   0   0   0   0   0   0   0]]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\r\n",
    "best_acc = 0\r\n",
    "best_act = ''\r\n",
    "best_m = 0\r\n",
    "for m in range(len(model)):\r\n",
    "    # predict on test\r\n",
    "    Y_pred = np.argmax(model[m].predict(X_test), axis = 1)\r\n",
    "    conf_mat = confusion_matrix(Y_test, Y_pred)\r\n",
    "    # get accuracy\r\n",
    "    _, train_acc = model[m].evaluate(X_train, to_categorical(Y_train), verbose=0)\r\n",
    "    _, test_acc = model[m].evaluate(X_test, to_categorical(Y_test), verbose=0)\r\n",
    "    a = acts[int(m/5)] + '-' + acts[m%5]\r\n",
    "    print('Activations: ', a)\r\n",
    "    print('Train Accuracy: ', round(train_acc*100, 2))\r\n",
    "    print('Test Accuracy: ', round(test_acc*100, 2))\r\n",
    "    print('Predicted Values: ', Y_pred)\r\n",
    "    print('Confusion Matrix:\\n', conf_mat)\r\n",
    "    print('---------------------------------')\r\n",
    "    if test_acc > best_acc:\r\n",
    "        best_acc = test_acc\r\n",
    "        best_act = a\r\n",
    "        best_m = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoB2YRhdnZEs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612620969909E12,
     "user_tz": -210.0,
     "elapsed": 1012.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "9c1a8806-b638-48fa-957e-91d16fc3ee26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Activations:  relu-sigmoid\n",
      "Best Accuracy on test set:  83.62\n"
     ]
    }
   ],
   "source": [
    "print('Best Activations: ', best_act)\r\n",
    "print('Best Accuracy on test set: ', round(100*best_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281.0
    },
    "id": "XJYNGRksUJL6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612619427508E12,
     "user_tz": -210.0,
     "elapsed": 1212.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "e48ad58b-615a-4396-837c-dd6cdba297ae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph cost function\r\n",
    "plt.title('Cost for ' + best_act)\r\n",
    "plt.plot(info[best_m].history['loss'], label='train')\r\n",
    "plt.plot(info[best_m].history['val_loss'], label='test')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho62WP3qqOTH"
   },
   "source": [
    "# C6. K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0O4AiQFqOTH"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FIE9dYQs0L6Z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612710493971E12,
     "user_tz": -210.0,
     "elapsed": 1102.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "# read file\r\n",
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wz4EnoeV0L6c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612712203846E12,
     "user_tz": -210.0,
     "elapsed": 1002.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "# split X and Y\n",
    "Y = df['variety'].to_numpy()\n",
    "X = df.drop(labels=df.columns[-1], axis='columns', inplace=False).to_numpy()\n",
    "# print(X)\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtZJZI2LqOTM"
   },
   "source": [
    "## C6.1. Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ib_3U_8jRmc-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.61271506596E12,
     "user_tz": -210.0,
     "elapsed": 968.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "def k_means(matrix, k, max_iterations = 100):\r\n",
    "    random.seed(37) # get same random numbers each run\r\n",
    "    n, m = matrix.shape # get m and n\r\n",
    "    means = np.zeros(shape = (k, m)) # means of clusters\r\n",
    "    r = random.sample(range(n), k) # get k initial points\r\n",
    "    for i in range(k):\r\n",
    "        means[i] = matrix[r[i]] # set k points as means\r\n",
    "    clusters = [] # each cluster have some points\r\n",
    "    iter = 0 # initialize iteration\r\n",
    "    while iter < max_iterations:\r\n",
    "        # update clustering\r\n",
    "        new_clusters = []\r\n",
    "        for i in range(k):\r\n",
    "            new_clusters.append([])\r\n",
    "        for i in range(n):\r\n",
    "            min_dist = float('inf')\r\n",
    "            c = 0\r\n",
    "            for j in range(k):\r\n",
    "                dist = np.linalg.norm(matrix[i] - means[j]) # Euclidean distance between point i and mean j\r\n",
    "                if dist < min_dist:\r\n",
    "                    min_dist = dist\r\n",
    "                    c = j\r\n",
    "            new_clusters[c].append(i) # assign point i to its nearest cluster\r\n",
    "        # recalculate means\r\n",
    "        diff = 0\r\n",
    "        for j in range(k):\r\n",
    "            # create a numpy array for each cluster using actual point values, not point number\r\n",
    "            c = []\r\n",
    "            for i in range(len(new_clusters[j])):\r\n",
    "                c.append(matrix[new_clusters[j][i]])\r\n",
    "            c = np.array(c)\r\n",
    "            # get mean of the cluster\r\n",
    "            means[j] = np.average(c, axis = 0)\r\n",
    "            # check if no change\r\n",
    "            if iter == 0: # ignore 1st iteration\r\n",
    "                continue\r\n",
    "            if set(new_clusters[j]) == set(clusters[j]): # same clustering for class[j]\r\n",
    "                diff += 1\r\n",
    "        if diff == k: # no change in clustering\r\n",
    "            break\r\n",
    "        # keep old clustering\r\n",
    "        clusters = new_clusters\r\n",
    "        # next interation\r\n",
    "        iter += 1\r\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-y3pxC-42op",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612715074567E12,
     "user_tz": -210.0,
     "elapsed": 986.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "7def18a4-6474-4110-bf65-b04ade312fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 106, 113, 114, 119, 121, 123, 126, 127, 133, 138, 142, 146, 149], [50, 52, 77, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 120, 122, 124, 125, 128, 129, 130, 131, 132, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 147, 148], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]]\n"
     ]
    }
   ],
   "source": [
    "k = 3 # set number of expected clusters\r\n",
    "c = k_means(X, k) # get clustering\r\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpVasAuqqOTP"
   },
   "source": [
    "## C6.2. Plot clusters in 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xNHXbA99qOTQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612715126703E12,
     "user_tz": -210.0,
     "elapsed": 1840.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "be8a1662-5ef9-4cd6-88ac-3d2fa630c105"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n, m = X.shape # get n and m\r\n",
    "labels = df.columns.values # get feature names\r\n",
    "for i in range(m):\r\n",
    "    for j in range(i+1, m):\r\n",
    "        fig = plt.figure()\r\n",
    "        for l in range(k):\r\n",
    "            plt.scatter(*X[c[l]][:, [i, j]].T)\r\n",
    "        plt.xlabel(labels[i])\r\n",
    "        plt.ylabel(labels[j])\r\n",
    "        fig.suptitle('Clustering by ' + labels[i] + ' - ' + labels[j])\r\n",
    "        plt.show()\r\n",
    "        print('----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_OUM1TqOTQ"
   },
   "source": [
    "## C6.3. Redundant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "hlZa7ILWHd5L",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612715627778E12,
     "user_tz": -210.0,
     "elapsed": 970.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "def cluster_acc(Y_true, Y_pred): # calculate accuracy of a clustering based on true and predicted values\r\n",
    "    Y_true = Y_true.astype(np.int64)\r\n",
    "    assert Y_pred.size == Y_true.size\r\n",
    "    D = max(Y_pred.max(), Y_true.max()) + 1\r\n",
    "    w = np.zeros((D, D), dtype=np.int64)\r\n",
    "    for i in range(Y_pred.size):\r\n",
    "        w[Y_pred[i], Y_true[i]] += 1\r\n",
    "    ind = linear_assignment(w.max() - w)\r\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / Y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "QtEZ2oSwYwHv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612716390131E12,
     "user_tz": -210.0,
     "elapsed": 990.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    }
   },
   "outputs": [],
   "source": [
    "# get unique output types\r\n",
    "y_labels = np.unique(Y)\r\n",
    "# make a dictionary mapping labels to integers\r\n",
    "d = dict(zip(list(y_labels), range(1, k+1))) \r\n",
    "# map real values to numeric values\r\n",
    "Y_numeric = np.vectorize(d.get)(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ396wzlcYzd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.61271744062E12,
     "user_tz": -210.0,
     "elapsed": 600.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "bbda2aa6-63db-4b4f-ecfe-5f8a1e2209d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering accuracy with ALL features:  88.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# get accuracy for the clustering\r\n",
    "c = k_means(X, k)\r\n",
    "Y_pred = [] # get predicted values of clustering\r\n",
    "for i in range(n):\r\n",
    "    for j in range(k):\r\n",
    "        if i in c[j]: \r\n",
    "            Y_pred.append(j+1)\r\n",
    "            break\r\n",
    "# get accuracy of clustering\r\n",
    "acc = cluster_acc(np.array(Y_numeric), np.array(Y_pred)) \r\n",
    "print('clustering accuracy with ALL features: ', round(acc*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "C6BdQhM_qOTQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.612717463187E12,
     "user_tz": -210.0,
     "elapsed": 1019.0,
     "user": {
      "displayName": "Arman Hafizi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNOXNhaUexdGuWz7ZhxsUkh-WdePFcHiLbJN3cOw=s64",
      "userId": "08055320445685541316"
     }
    },
    "outputId": "6bc2f7a2-2902-4f9f-a2e0-e6ce1a7034da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering accuracy WITHOUT feature sepal.length:  95.33\n",
      "clustering accuracy WITHOUT feature sepal.width:  90.67\n",
      "clustering accuracy WITHOUT feature petal.length:  82.67\n",
      "clustering accuracy WITHOUT feature petal.width:  88.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# repeat procedure using m-1 features\r\n",
    "for f in range(m):\r\n",
    "    # all features except feature f\r\n",
    "    features = list(range(m))\r\n",
    "    features.remove(f)\r\n",
    "    X_this = X[:, features] # filter X using new features\r\n",
    "    # print(X_this)\r\n",
    "    c = k_means(X_this, k) # get clustering for the new set of X\r\n",
    "    # get predicted values of clustering\r\n",
    "    Y_pred = []\r\n",
    "    for i in range(n):\r\n",
    "        for j in range(k):\r\n",
    "            if i in c[j]: \r\n",
    "                Y_pred.append(j+1)\r\n",
    "                break\r\n",
    "    # get accuracy of clustering\r\n",
    "    acc = cluster_acc(np.array(Y_numeric), np.array(Y_pred)) \r\n",
    "    print('clustering accuracy WITHOUT feature ' + labels[f] + ': ', round(acc*100, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "name": "HW6.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "PrQrcHdwqOSF",
    "JL3fvWVhqOSX",
    "2brLWtFeqOSv",
    "EeqF_PxR-dX5",
    "yBB0YKkmqOS_",
    "be_wzUsHqOTB",
    "1w7XS99GqOTC",
    "7jFNDFOiqOTD",
    "gqeUewoVqOTE",
    "Ho62WP3qqOTH",
    "l0O4AiQFqOTH",
    "wtZJZI2LqOTM",
    "PpVasAuqqOTP",
    "cv_OUM1TqOTQ"
   ],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
